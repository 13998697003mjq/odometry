{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PWC-Net-small model training (with cyclical learning rate schedule)\n",
    "=======================================================\n",
    "\n",
    "In this notebook we:\n",
    "- Use a small model (no dense or residual connections), 6 level pyramid, uspample level 2 by 4 as the final flow prediction\n",
    "- Train the PWC-Net-small model on a mix of the `FlyingChairs` and `FlyingThings3DHalfRes` dataset using a Cyclic<sub>short</sub> schedule of our own\n",
    "- The Cyclic<sub>short</sub> schedule oscillates between `5e-04` and `1e-05` for 200,000 steps\n",
    "\n",
    "Below, look for `TODO` references and customize this notebook based on your own needs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reference\n",
    "\n",
    "[2018a]<a name=\"2018a\"></a> Sun et al. 2018. PWC-Net: CNNs for Optical Flow Using Pyramid, Warping, and Cost Volume. [[arXiv]](https://arxiv.org/abs/1709.02371) [[web]](http://research.nvidia.com/publication/2018-02_PWC-Net%3A-CNNs-for) [[PyTorch (Official)]](https://github.com/NVlabs/PWC-Net/tree/master/PyTorch) [[Caffe (Official)]](https://github.com/NVlabs/PWC-Net/tree/master/Caffe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "pwcnet_train.ipynb\n",
    "\n",
    "PWC-Net model training.\n",
    "\n",
    "Written by Phil Ferriere\n",
    "\n",
    "Licensed under the MIT License (see LICENSE for details)\n",
    "\n",
    "Tensorboard:\n",
    "    [win] tensorboard --logdir=E:\\\\repos\\\\tf-optflow\\\\tfoptflow\\\\pwcnet-sm-6-2-cyclic-chairsthingsmix\n",
    "    [ubu] tensorboard --logdir=/media/EDrive/repos/tf-optflow/tfoptflow/pwcnet-sm-6-2-cyclic-chairsthingsmix\n",
    "\"\"\"\n",
    "from __future__ import absolute_import, division, print_function\n",
    "import sys\n",
    "from copy import deepcopy\n",
    "\n",
    "from dataset_base import _DEFAULT_DS_TRAIN_OPTIONS\n",
    "from dataset_flyingchairs import FlyingChairsDataset\n",
    "from dataset_flyingthings3d import FlyingThings3DHalfResDataset\n",
    "from dataset_mixer import MixedDataset\n",
    "from model_pwcnet import ModelPWCNet, _DEFAULT_PWCNET_TRAIN_OPTIONS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO: Set this first!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: You MUST set dataset_root to the correct path on your machine!\n",
    "if sys.platform.startswith(\"win\"):\n",
    "    _DATASET_ROOT = 'E:/datasets/'\n",
    "else:\n",
    "    _DATASET_ROOT = '/Vol1/dbstore/datasets/'\n",
    "_FLYINGCHAIRS_ROOT = _DATASET_ROOT + 'FlyingChairs_release'\n",
    "_FLYINGTHINGS3DHALFRES_ROOT = _DATASET_ROOT + 'FlyingThings3D_release'\n",
    "    \n",
    "# TODO: You MUST adjust the settings below based on the number of GPU(s) used for training\n",
    "# Set controller device and devices\n",
    "# A one-gpu setup would be something like controller='/device:GPU:0' and gpu_devices=['/device:GPU:0']\n",
    "# Here, we use a dual-GPU setup, as shown below\n",
    "gpu_devices = ['/device:GPU:2']\n",
    "controller = '/device:GPU:0'\n",
    "\n",
    "# TODO: You MUST adjust this setting below based on the amount of memory on your GPU(s)\n",
    "# Batch size\n",
    "batch_size = 18"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-train on `FlyingChairs+FlyingThings3DHalfRes` mix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: You MUST set the batch size based on the capabilities of your GPU(s) \n",
    "#  Load train dataset\n",
    "ds_opts = deepcopy(_DEFAULT_DS_TRAIN_OPTIONS)\n",
    "ds_opts['in_memory'] = False                          # Too many samples to keep in memory at once, so don't preload them\n",
    "ds_opts['aug_type'] = 'heavy'                         # Apply all supported augmentations\n",
    "ds_opts['batch_size'] = batch_size * len(gpu_devices) # Use a multiple of 8; here, 16 for dual-GPU mode (Titan X & 1080 Ti)\n",
    "ds_opts['crop_preproc'] = (256, 448)                  # Crop to a smaller input size\n",
    "ds1 = FlyingChairsDataset(mode='train_with_val', ds_root=_FLYINGCHAIRS_ROOT, options=ds_opts)\n",
    "ds_opts['type'] = 'into_future'\n",
    "ds2 = FlyingThings3DHalfResDataset(mode='train_with_val', ds_root=_FLYINGTHINGS3DHALFRES_ROOT, options=ds_opts)\n",
    "ds = MixedDataset(mode='train_with_val', datasets=[ds1, ds2], options=ds_opts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset Configuration:\n",
      "  verbose              False\n",
      "  in_memory            False\n",
      "  crop_preproc         (256, 448)\n",
      "  scale_preproc        None\n",
      "  tb_test_imgs         False\n",
      "  random_seed          1969\n",
      "  val_split            0.03\n",
      "  aug_type             heavy\n",
      "  aug_labels           True\n",
      "  fliplr               0.5\n",
      "  flipud               0.5\n",
      "  translate            (0.5, 0.05)\n",
      "  scale                (0.5, 0.05)\n",
      "  batch_size           18\n",
      "  type                 into_future\n",
      "  mode                 train_with_val\n",
      "  train size           41731\n",
      "  val size             1292\n"
     ]
    }
   ],
   "source": [
    "# Display dataset configuration\n",
    "ds.print_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure the training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start from the default options\n",
    "nn_opts = deepcopy(_DEFAULT_PWCNET_TRAIN_OPTIONS)\n",
    "nn_opts['verbose'] = True\n",
    "nn_opts['ckpt_dir'] = './pwcnet-sm-6-2-cyclic-chairsthingsmix/'\n",
    "nn_opts['batch_size'] = ds_opts['batch_size']\n",
    "nn_opts['x_shape'] = [2, ds_opts['crop_preproc'][0], ds_opts['crop_preproc'][1], 3]\n",
    "nn_opts['y_shape'] = [ds_opts['crop_preproc'][0], ds_opts['crop_preproc'][1], 2]\n",
    "nn_opts['use_tf_data'] = True # Use tf.data reader\n",
    "nn_opts['gpu_devices'] = gpu_devices\n",
    "nn_opts['controller'] = controller\n",
    "\n",
    "# Use the PWC-Net-small model in quarter-resolution mode\n",
    "nn_opts['use_dense_cx'] = False\n",
    "nn_opts['use_res_cx'] = False\n",
    "nn_opts['pyr_lvls'] = 6\n",
    "nn_opts['flow_pred_lvl'] = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the learning rate schedule. This schedule is for a single GPU using a batch size of 8.\n",
    "# Below,we adjust the schedule to the size of the batch and the number of GPUs.\n",
    "nn_opts['lr_policy'] = 'cyclic'\n",
    "nn_opts['cyclic_lr_max'] = 5e-04 # Anything higher will generate NaNs\n",
    "nn_opts['cyclic_lr_base'] = 1e-05\n",
    "nn_opts['cyclic_lr_stepsize'] = 20000\n",
    "nn_opts['max_steps'] = 200000\n",
    "\n",
    "# Below,we adjust the schedule to the size of the batch and our number of GPUs (2).\n",
    "nn_opts['max_steps'] = int(nn_opts['max_steps'] * 8 / ds_opts['batch_size'])\n",
    "nn_opts['cyclic_lr_stepsize'] = int(nn_opts['cyclic_lr_stepsize'] * 8 / ds_opts['batch_size'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building model...\n",
      "... model built.\n",
      "Configuring training ops...\n",
      "... training ops configured.\n",
      "Initializing model from previous checkpoint ./pwcnet-sm-6-2-cyclic-chairsthingsmix/pwcnet.ckpt-57000 to resume training...\n",
      "\n",
      "INFO:tensorflow:Restoring parameters from ./pwcnet-sm-6-2-cyclic-chairsthingsmix/pwcnet.ckpt-57000\n",
      "... model initialized\n",
      "\n",
      "Model Configuration:\n",
      "  verbose                True\n",
      "  ckpt_dir               ./pwcnet-sm-6-2-cyclic-chairsthingsmix/\n",
      "  max_to_keep            10\n",
      "  x_dtype                <dtype: 'float32'>\n",
      "  x_shape                [2, 256, 448, 3]\n",
      "  y_dtype                <dtype: 'float32'>\n",
      "  y_shape                [256, 448, 2]\n",
      "  train_mode             train\n",
      "  adapt_info             None\n",
      "  sparse_gt_flow         False\n",
      "  display_step           100\n",
      "  snapshot_step          1000\n",
      "  val_step               1000\n",
      "  val_batch_size         -1\n",
      "  tb_val_imgs            pyramid\n",
      "  tb_test_imgs           None\n",
      "  gpu_devices            ['/device:GPU:2']\n",
      "  controller             /device:GPU:0\n",
      "  use_tf_data            True\n",
      "  use_mixed_precision    False\n",
      "  loss_scaler            128.0\n",
      "  batch_size             18\n",
      "  lr_policy              cyclic\n",
      "  max_steps              88888\n",
      "  cyclic_lr_max          0.0005\n",
      "  cyclic_lr_base         1e-05\n",
      "  cyclic_lr_stepsize     8888\n",
      "  loss_fn                loss_multiscale\n",
      "  alphas                 [0.32, 0.08, 0.02, 0.01, 0.005, 0.0025]\n",
      "  gamma                  0.0004\n",
      "  q                      1.0\n",
      "  epsilon                0.0\n",
      "  pyr_lvls               6\n",
      "  flow_pred_lvl          3\n",
      "  search_range           4\n",
      "  use_dense_cx           False\n",
      "  use_res_cx             False\n",
      "  mode                   train_with_val\n",
      "  trainable params       4236386\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the model and display the model configuration\n",
    "nn = ModelPWCNet(mode='train_with_val', options=nn_opts, dataset=ds)\n",
    "nn.print_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resume training from step 57001...\n",
      "WARNING:tensorflow:From /Vol0/user/f.konokhov/tfoptflow/tfoptflow/dataset_base.py:1062: shuffle_and_repeat (from tensorflow.contrib.data.python.ops.shuffle_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.experimental.shuffle_and_repeat(...)`.\n",
      "WARNING:tensorflow:From /Vol0/user/f.konokhov/tfoptflow/tfoptflow/dataset_base.py:1065: map_and_batch (from tensorflow.contrib.data.python.ops.batching) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.experimental.map_and_batch(...)`.\n",
      "2019-04-19 13:03:48 Iter 57100 [Train]: loss=87.17, epe=27.31, lr=0.000036, samples/sec=25.1, sec/step=0.718, eta=6:20:17\n",
      "2019-04-19 13:04:44 Iter 57200 [Train]: loss=95.55, epe=30.29, lr=0.000037, samples/sec=36.1, sec/step=0.499, eta=4:23:18\n",
      "2019-04-19 13:05:41 Iter 57300 [Train]: loss=83.09, epe=25.99, lr=0.000037, samples/sec=35.3, sec/step=0.510, eta=4:28:34\n",
      "2019-04-19 13:06:37 Iter 57400 [Train]: loss=91.28, epe=28.53, lr=0.000038, samples/sec=35.9, sec/step=0.502, eta=4:23:26\n",
      "2019-04-19 13:07:34 Iter 57500 [Train]: loss=89.14, epe=27.93, lr=0.000039, samples/sec=35.8, sec/step=0.503, eta=4:23:19\n",
      "2019-04-19 13:08:29 Iter 57600 [Train]: loss=80.98, epe=25.36, lr=0.000039, samples/sec=36.1, sec/step=0.498, eta=4:19:53\n",
      "2019-04-19 13:09:24 Iter 57700 [Train]: loss=86.39, epe=27.13, lr=0.000040, samples/sec=36.2, sec/step=0.498, eta=4:18:39\n",
      "2019-04-19 13:10:17 Iter 57800 [Train]: loss=93.63, epe=29.33, lr=0.000041, samples/sec=36.9, sec/step=0.487, eta=4:12:26\n",
      "2019-04-19 13:11:12 Iter 57900 [Train]: loss=92.09, epe=28.82, lr=0.000042, samples/sec=36.2, sec/step=0.497, eta=4:16:28\n",
      "2019-04-19 13:12:04 Iter 58000 [Train]: loss=83.90, epe=26.25, lr=0.000042, samples/sec=37.4, sec/step=0.481, eta=4:07:50\n",
      "2019-04-19 13:12:28 Iter 58000 [Val]: loss=85.77, epe=26.55\n",
      "Saving model...\n",
      "... model wasn't saved -- its score (26.55) doesn't outperform other checkpoints\n",
      "2019-04-19 13:13:44 Iter 58100 [Train]: loss=85.75, epe=26.86, lr=0.000043, samples/sec=36.2, sec/step=0.497, eta=4:15:08\n",
      "2019-04-19 13:14:37 Iter 58200 [Train]: loss=89.91, epe=28.15, lr=0.000044, samples/sec=37.0, sec/step=0.487, eta=4:08:57\n",
      "2019-04-19 13:15:31 Iter 58300 [Train]: loss=86.84, epe=27.19, lr=0.000044, samples/sec=36.6, sec/step=0.491, eta=4:10:24\n",
      "2019-04-19 13:16:24 Iter 58400 [Train]: loss=86.10, epe=26.93, lr=0.000045, samples/sec=36.6, sec/step=0.492, eta=4:10:12\n",
      "2019-04-19 13:17:19 Iter 58500 [Train]: loss=116.30, epe=36.27, lr=0.000046, samples/sec=36.4, sec/step=0.495, eta=4:10:41\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "nn.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are the training curves for the run above:\n",
    "\n",
    "![](img/pwcnet-sm-6-2-cyclic-chairsthingsmix/loss.png)\n",
    "![](img/pwcnet-sm-6-2-cyclic-chairsthingsmix/epe.png)\n",
    "![](img/pwcnet-sm-6-2-cyclic-chairsthingsmix/lr.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are the predictions issued by the model for a few validation samples:\n",
    "\n",
    "![](img/pwcnet-sm-6-2-cyclic-chairsthingsmix/val1.png)\n",
    "![](img/pwcnet-sm-6-2-cyclic-chairsthingsmix/val2.png)\n",
    "![](img/pwcnet-sm-6-2-cyclic-chairsthingsmix/val3.png)\n",
    "![](img/pwcnet-sm-6-2-cyclic-chairsthingsmix/val4.png)\n",
    "![](img/pwcnet-sm-6-2-cyclic-chairsthingsmix/val5.png)\n",
    "![](img/pwcnet-sm-6-2-cyclic-chairsthingsmix/val6.png)\n",
    "![](img/pwcnet-sm-6-2-cyclic-chairsthingsmix/val7.png)\n",
    "![](img/pwcnet-sm-6-2-cyclic-chairsthingsmix/val8.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
