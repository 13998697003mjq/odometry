{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PWC-Net-small model mixed-precision training (with cyclical learning rate schedule)\n",
    "=======================================================\n",
    "\n",
    "In this notebook we:\n",
    "- Use a small model (no dense or residual connections), 6 level pyramid, uspample level 2 by 4 as the final flow prediction\n",
    "- Train the PWC-Net-small model on a mix of the `FlyingChairs` and `FlyingThings3DHalfRes` dataset using a Cyclic<sub>short</sub> schedule of our own\n",
    "- The Cyclic<sub>short</sub> schedule oscillates between `5e-04` and `1e-05` for 200,000 steps with a stepsize of `40,000`\n",
    "- The training is done using mixed-precision with a loss scaler of `128.0` and a batch size of `32`\n",
    "\n",
    "Below, look for `TODO` references and customize this notebook based on your own needs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reference\n",
    "\n",
    "[2018a]<a name=\"2018a\"></a> Sun et al. 2018. PWC-Net: CNNs for Optical Flow Using Pyramid, Warping, and Cost Volume. [[arXiv]](https://arxiv.org/abs/1709.02371) [[web]](http://research.nvidia.com/publication/2018-02_PWC-Net%3A-CNNs-for) [[PyTorch (Official)]](https://github.com/NVlabs/PWC-Net/tree/master/PyTorch) [[Caffe (Official)]](https://github.com/NVlabs/PWC-Net/tree/master/Caffe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "pwcnet_train.ipynb\n",
    "\n",
    "PWC-Net model training.\n",
    "\n",
    "Written by Phil Ferriere\n",
    "\n",
    "Licensed under the MIT License (see LICENSE for details)\n",
    "\n",
    "Tensorboard:\n",
    "    [win] tensorboard --logdir=E:\\\\repos\\\\tf-optflow\\\\tfoptflow\\\\pwcnet-sm-6-2-cyclic-chairsthingsmix-fp16\n",
    "    [ubu] tensorboard --logdir=/media/EDrive/repos/tf-optflow/tfoptflow/pwcnet-sm-6-2-cyclic-chairsthingsmix-fp16\n",
    "\"\"\"\n",
    "from __future__ import absolute_import, division, print_function\n",
    "import sys\n",
    "from copy import deepcopy\n",
    "import tensorflow as tf\n",
    "\n",
    "from dataset_base import _DEFAULT_DS_TRAIN_OPTIONS\n",
    "from dataset_flyingchairs import FlyingChairsDataset\n",
    "from dataset_flyingthings3d import FlyingThings3DHalfResDataset\n",
    "from dataset_mixer import MixedDataset\n",
    "from model_pwcnet import ModelPWCNet, _DEFAULT_PWCNET_TRAIN_OPTIONS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO: Set this first!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: You MUST set dataset_root to the correct path on your machine!\n",
    "if sys.platform.startswith(\"win\"):\n",
    "    _DATASET_ROOT = 'E:/datasets/'\n",
    "else:\n",
    "    _DATASET_ROOT = '/Vol1/dbstore/datasets/'\n",
    "_FLYINGCHAIRS_ROOT = _DATASET_ROOT + 'FlyingChairs_release'\n",
    "_FLYINGTHINGS3DHALFRES_ROOT = _DATASET_ROOT + 'FlyingThings3D_HalfRes'\n",
    "    \n",
    "# TODO: You MUST adjust the settings below based on the number of GPU(s) used for training\n",
    "# Set controller device and devices\n",
    "# A one-gpu setup would be something like controller='/device:GPU:0' and gpu_devices=['/device:GPU:0']\n",
    "# Here, we use a dual-GPU setup, as shown below\n",
    "gpu_devices = ['/device:GPU:0', '/device:GPU:1']\n",
    "controller = '/device:GPU:0'\n",
    "\n",
    "# TODO: You MUST adjust this setting below based on the amount of memory on your GPU(s)\n",
    "# Batch size\n",
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train on `FlyingChairs+FlyingThings3DHalfRes` mix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: You MUST set the batch size based on the capabilities of your GPU(s) \n",
    "#  Load train dataset\n",
    "ds_opts = deepcopy(_DEFAULT_DS_TRAIN_OPTIONS)\n",
    "ds_opts['in_memory'] = False                          # Too many samples to keep in memory at once, so don't preload them\n",
    "ds_opts['aug_type'] = 'heavy'                         # Apply all supported augmentations\n",
    "ds_opts['batch_size'] = batch_size * len(gpu_devices) # Use a multiple of 8; here, 16 for dual-GPU mode (Titan X & 1080 Ti)\n",
    "ds_opts['crop_preproc'] = (256, 448)                  # Crop to a smaller input size\n",
    "ds1 = FlyingChairsDataset(mode='train_with_val', ds_root=_FLYINGCHAIRS_ROOT, options=ds_opts)\n",
    "ds_opts['type'] = 'into_future'\n",
    "ds2 = FlyingThings3DHalfResDataset(mode='train_with_val', ds_root=_FLYINGTHINGS3DHALFRES_ROOT, options=ds_opts)\n",
    "ds = MixedDataset(mode='train_with_val', datasets=[ds1, ds2], options=ds_opts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset Configuration:\n",
      "  verbose              False\n",
      "  in_memory            False\n",
      "  crop_preproc         (256, 448)\n",
      "  scale_preproc        None\n",
      "  tb_test_imgs         False\n",
      "  random_seed          1969\n",
      "  val_split            0.03\n",
      "  aug_type             heavy\n",
      "  aug_labels           True\n",
      "  fliplr               0.5\n",
      "  flipud               0.5\n",
      "  translate            (0.5, 0.05)\n",
      "  scale                (0.5, 0.05)\n",
      "  batch_size           32\n",
      "  type                 into_future\n",
      "  mode                 train_with_val\n",
      "  train size           41731\n",
      "  val size             1292\n"
     ]
    }
   ],
   "source": [
    "# Display dataset configuration\n",
    "ds.print_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure the training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start from the default options\n",
    "nn_opts = deepcopy(_DEFAULT_PWCNET_TRAIN_OPTIONS)\n",
    "nn_opts['verbose'] = True\n",
    "nn_opts['ckpt_dir'] = './pwcnet-sm-6-2-cyclic-chairsthingsmix-fp16/'\n",
    "nn_opts['batch_size'] = ds_opts['batch_size']\n",
    "nn_opts['x_shape'] = [2, ds_opts['crop_preproc'][0], ds_opts['crop_preproc'][1], 3]\n",
    "nn_opts['y_shape'] = [ds_opts['crop_preproc'][0], ds_opts['crop_preproc'][1], 2]\n",
    "nn_opts['use_tf_data'] = True # Use tf.data reader\n",
    "nn_opts['gpu_devices'] = gpu_devices\n",
    "nn_opts['controller'] = controller\n",
    "\n",
    "# Use the PWC-Net-small model in quarter-resolution mode\n",
    "nn_opts['use_dense_cx'] = False\n",
    "nn_opts['use_res_cx'] = False\n",
    "nn_opts['pyr_lvls'] = 6\n",
    "nn_opts['flow_pred_lvl'] = 2\n",
    "\n",
    "# Use mixed precision training\n",
    "nn_opts['use_mixed_precision'] = True \n",
    "nn_opts['loss_scaler'] = 128.\n",
    "nn_opts['x_dtype'] = tf.float32\n",
    "nn_opts['y_dtype'] = tf.float32\n",
    "\n",
    "# More options\n",
    "nn_opts['max_to_keep'] = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the learning rate schedule. This schedule is for a single GPU using a batch size of 8.\n",
    "# Below,we adjust the schedule to the size of the batch and the number of GPUs.\n",
    "nn_opts['lr_policy'] = 'cyclic'\n",
    "nn_opts['cyclic_lr_max'] = 5e-04\n",
    "nn_opts['cyclic_lr_base'] = 1e-05\n",
    "nn_opts['cyclic_lr_stepsize'] = 40000\n",
    "nn_opts['max_steps'] = 200000\n",
    "\n",
    "# Below,we adjust the schedule to the size of the batch and our number of GPUs (2).\n",
    "nn_opts['max_steps'] = int(nn_opts['max_steps'] * 8 / ds_opts['batch_size'])\n",
    "nn_opts['cyclic_lr_stepsize'] = int(nn_opts['cyclic_lr_stepsize'] * 8 / ds_opts['batch_size'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building model towers...\n",
      "  Building tower_0...\n",
      "  ...tower_0 built.\n",
      "  Building tower_1...\n",
      "  ...tower_1 built.\n",
      "... model towers built.\n",
      "Initializing model from previous checkpoint ./pwcnet-sm-6-2-cyclic-chairsthingsmix-fp16/pwcnet.ckpt-10000 to resume training...\n",
      "\n",
      "INFO:tensorflow:Restoring parameters from ./pwcnet-sm-6-2-cyclic-chairsthingsmix-fp16/pwcnet.ckpt-10000\n",
      "... model initialized\n",
      "\n",
      "Model Configuration:\n",
      "  verbose                True\n",
      "  ckpt_dir               ./pwcnet-sm-6-2-cyclic-chairsthingsmix-fp16/\n",
      "  max_to_keep            50\n",
      "  x_dtype                <dtype: 'float32'>\n",
      "  x_shape                [2, 256, 448, 3]\n",
      "  y_dtype                <dtype: 'float32'>\n",
      "  y_shape                [256, 448, 2]\n",
      "  train_mode             train\n",
      "  adapt_info             None\n",
      "  sparse_gt_flow         False\n",
      "  display_step           100\n",
      "  snapshot_step          1000\n",
      "  val_step               1000\n",
      "  val_batch_size         -1\n",
      "  tb_val_imgs            pyramid\n",
      "  tb_test_imgs           None\n",
      "  gpu_devices            ['/device:GPU:0', '/device:GPU:1']\n",
      "  controller             /device:GPU:0\n",
      "  use_tf_data            True\n",
      "  use_mixed_precision    True\n",
      "  loss_scaler            128.0\n",
      "  batch_size             32\n",
      "  lr_policy              cyclic\n",
      "  max_steps              50000\n",
      "  cyclic_lr_max          0.0005\n",
      "  cyclic_lr_base         1e-05\n",
      "  cyclic_lr_stepsize     10000\n",
      "  loss_fn                loss_multiscale\n",
      "  alphas                 [0.32, 0.08, 0.02, 0.01, 0.005, 0.0025]\n",
      "  gamma                  0.0004\n",
      "  q                      1.0\n",
      "  epsilon                0.0\n",
      "  pyr_lvls               6\n",
      "  flow_pred_lvl          2\n",
      "  search_range           4\n",
      "  use_dense_cx           False\n",
      "  use_res_cx             False\n",
      "  mode                   train_with_val\n",
      "  trainable params       4705064\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the model and display the model configuration\n",
    "nn = ModelPWCNet(mode='train_with_val', options=nn_opts, dataset=ds)\n",
    "nn.print_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resume training from step 18670...\n",
      "2019-04-22 10:52:42 Iter 18700 [Train]: loss=76.40, epe=5.74, lr=0.000074, samples/sec=59.6, sec/step=1.074, eta=9:20:19\n",
      "2019-04-22 10:56:21 Iter 18800 [Train]: loss=78.32, epe=5.89, lr=0.000069, samples/sec=60.0, sec/step=1.067, eta=9:14:49\n",
      "2019-04-22 11:00:02 Iter 18900 [Train]: loss=71.64, epe=5.37, lr=0.000064, samples/sec=60.1, sec/step=1.065, eta=9:11:52\n",
      "2019-04-22 11:03:40 Iter 19000 [Train]: loss=67.32, epe=4.99, lr=0.000059, samples/sec=59.9, sec/step=1.069, eta=9:12:25\n",
      "2019-04-22 11:04:05 Iter 19000 [Val]: loss=76.50, epe=5.71\n",
      "Saving model...\n",
      "INFO:tensorflow:./pwcnet-sm-6-2-cyclic-chairsthingsmix-fp16/pwcnet.ckpt-19000 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "... model saved in ./pwcnet-sm-6-2-cyclic-chairsthingsmix-fp16/pwcnet.ckpt-19000\n",
      "2019-04-22 11:08:16 Iter 19100 [Train]: loss=65.43, epe=4.83, lr=0.000054, samples/sec=60.0, sec/step=1.067, eta=9:09:43\n",
      "2019-04-22 11:11:57 Iter 19200 [Train]: loss=64.44, epe=4.75, lr=0.000049, samples/sec=59.9, sec/step=1.068, eta=9:08:10\n",
      "2019-04-22 11:15:39 Iter 19300 [Train]: loss=101.91, epe=8.13, lr=0.000044, samples/sec=60.0, sec/step=1.067, eta=9:05:57\n",
      "2019-04-22 11:19:18 Iter 19400 [Train]: loss=102.00, epe=7.47, lr=0.000039, samples/sec=60.0, sec/step=1.066, eta=9:03:46\n",
      "2019-04-22 11:22:56 Iter 19500 [Train]: loss=72.69, epe=5.51, lr=0.000035, samples/sec=59.8, sec/step=1.070, eta=9:03:44\n",
      "2019-04-22 11:26:35 Iter 19600 [Train]: loss=77.90, epe=5.86, lr=0.000030, samples/sec=59.7, sec/step=1.072, eta=9:02:58\n",
      "2019-04-22 11:30:15 Iter 19700 [Train]: loss=67.28, epe=4.98, lr=0.000025, samples/sec=59.9, sec/step=1.069, eta=8:59:58\n",
      "2019-04-22 11:33:54 Iter 19800 [Train]: loss=65.13, epe=4.81, lr=0.000020, samples/sec=60.0, sec/step=1.066, eta=8:56:47\n",
      "2019-04-22 11:37:35 Iter 19900 [Train]: loss=63.48, epe=4.66, lr=0.000015, samples/sec=59.8, sec/step=1.070, eta=8:56:43\n",
      "2019-04-22 11:41:14 Iter 20000 [Train]: loss=69.73, epe=5.07, lr=0.000010, samples/sec=59.9, sec/step=1.069, eta=8:54:33\n",
      "2019-04-22 11:41:37 Iter 20000 [Val]: loss=76.20, epe=5.69\n",
      "Saving model...\n",
      "INFO:tensorflow:./pwcnet-sm-6-2-cyclic-chairsthingsmix-fp16/pwcnet.ckpt-20000 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "... model saved in ./pwcnet-sm-6-2-cyclic-chairsthingsmix-fp16/pwcnet.ckpt-20000\n",
      "2019-04-22 11:45:47 Iter 20100 [Train]: loss=64.94, epe=4.79, lr=0.000012, samples/sec=60.0, sec/step=1.067, eta=8:51:51\n",
      "2019-04-22 11:49:21 Iter 20200 [Train]: loss=64.83, epe=4.78, lr=0.000015, samples/sec=60.5, sec/step=1.058, eta=8:45:30\n",
      "2019-04-22 11:52:58 Iter 20300 [Train]: loss=77.58, epe=5.83, lr=0.000017, samples/sec=60.0, sec/step=1.066, eta=8:47:43\n",
      "2019-04-22 11:56:31 Iter 20400 [Train]: loss=67.27, epe=4.97, lr=0.000020, samples/sec=60.5, sec/step=1.058, eta=8:42:04\n",
      "2019-04-22 12:00:09 Iter 20500 [Train]: loss=64.55, epe=4.75, lr=0.000022, samples/sec=60.2, sec/step=1.064, eta=8:43:00\n",
      "2019-04-22 12:04:11 Iter 20600 [Train]: loss=65.09, epe=4.80, lr=0.000025, samples/sec=56.1, sec/step=1.140, eta=9:18:35\n",
      "2019-04-22 12:08:28 Iter 20700 [Train]: loss=96.77, epe=7.90, lr=0.000027, samples/sec=55.1, sec/step=1.161, eta=9:26:47\n",
      "2019-04-22 12:12:37 Iter 20800 [Train]: loss=63.84, epe=4.70, lr=0.000030, samples/sec=55.0, sec/step=1.163, eta=9:26:07\n",
      "2019-04-22 12:16:53 Iter 20900 [Train]: loss=67.28, epe=5.05, lr=0.000032, samples/sec=53.2, sec/step=1.204, eta=9:43:43\n",
      "2019-04-22 12:21:03 Iter 21000 [Train]: loss=115.40, epe=9.53, lr=0.000034, samples/sec=54.9, sec/step=1.165, eta=9:23:09\n",
      "2019-04-22 12:21:30 Iter 21000 [Val]: loss=73.29, epe=5.45\n",
      "Saving model...\n",
      "INFO:tensorflow:./pwcnet-sm-6-2-cyclic-chairsthingsmix-fp16/pwcnet.ckpt-21000 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "... model saved in ./pwcnet-sm-6-2-cyclic-chairsthingsmix-fp16/pwcnet.ckpt-21000\n",
      "2019-04-22 12:26:34 Iter 21100 [Train]: loss=65.07, epe=4.80, lr=0.000037, samples/sec=54.7, sec/step=1.170, eta=9:23:34\n",
      "2019-04-22 12:30:48 Iter 21200 [Train]: loss=64.41, epe=4.75, lr=0.000039, samples/sec=54.0, sec/step=1.185, eta=9:28:37\n",
      "2019-04-22 12:35:00 Iter 21300 [Train]: loss=77.37, epe=5.82, lr=0.000042, samples/sec=54.5, sec/step=1.174, eta=9:21:24\n",
      "2019-04-22 12:39:08 Iter 21400 [Train]: loss=66.42, epe=4.91, lr=0.000044, samples/sec=54.7, sec/step=1.169, eta=9:17:21\n",
      "2019-04-22 12:43:19 Iter 21500 [Train]: loss=72.59, epe=5.38, lr=0.000047, samples/sec=54.9, sec/step=1.167, eta=9:14:06\n",
      "2019-04-22 12:47:34 Iter 21600 [Train]: loss=95.59, epe=7.58, lr=0.000049, samples/sec=54.2, sec/step=1.181, eta=9:19:06\n",
      "2019-04-22 12:51:52 Iter 21700 [Train]: loss=64.62, epe=4.86, lr=0.000052, samples/sec=55.0, sec/step=1.163, eta=9:08:45\n",
      "2019-04-22 12:56:03 Iter 21800 [Train]: loss=64.98, epe=4.80, lr=0.000054, samples/sec=54.9, sec/step=1.165, eta=9:07:43\n",
      "2019-04-22 13:00:23 Iter 21900 [Train]: loss=76.08, epe=nan, lr=0.000057, samples/sec=53.9, sec/step=1.187, eta=9:15:56\n",
      "2019-04-22 13:04:39 Iter 22000 [Train]: loss=65.55, epe=4.85, lr=0.000059, samples/sec=54.1, sec/step=1.182, eta=9:11:47\n",
      "2019-04-22 13:05:06 Iter 22000 [Val]: loss=74.30, epe=5.53\n",
      "Saving model...\n",
      "INFO:tensorflow:./pwcnet-sm-6-2-cyclic-chairsthingsmix-fp16/pwcnet.ckpt-22000 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "... model saved in ./pwcnet-sm-6-2-cyclic-chairsthingsmix-fp16/pwcnet.ckpt-22000\n",
      "2019-04-22 13:10:04 Iter 22100 [Train]: loss=129.65, epe=7.81, lr=0.000061, samples/sec=54.1, sec/step=1.183, eta=9:10:13\n",
      "2019-04-22 13:14:28 Iter 22200 [Train]: loss=64.24, epe=4.73, lr=0.000064, samples/sec=53.9, sec/step=1.187, eta=9:10:03\n",
      "2019-04-22 13:18:52 Iter 22300 [Train]: loss=67.19, epe=4.97, lr=0.000066, samples/sec=54.4, sec/step=1.177, eta=9:03:26\n",
      "2019-04-22 13:23:10 Iter 22400 [Train]: loss=64.60, epe=4.76, lr=0.000069, samples/sec=54.0, sec/step=1.185, eta=9:04:55\n",
      "2019-04-22 13:27:29 Iter 22500 [Train]: loss=72.49, epe=5.41, lr=0.000071, samples/sec=53.7, sec/step=1.191, eta=9:05:47\n",
      "2019-04-22 13:31:43 Iter 22600 [Train]: loss=74.37, epe=5.56, lr=0.000074, samples/sec=54.2, sec/step=1.181, eta=8:59:33\n",
      "2019-04-22 13:36:02 Iter 22700 [Train]: loss=67.26, epe=4.98, lr=0.000076, samples/sec=54.1, sec/step=1.182, eta=8:57:51\n",
      "2019-04-22 13:40:35 Iter 22800 [Train]: loss=91.81, epe=7.28, lr=0.000079, samples/sec=52.9, sec/step=1.209, eta=9:07:57\n",
      "2019-04-22 13:44:53 Iter 22900 [Train]: loss=65.07, epe=4.80, lr=0.000081, samples/sec=54.1, sec/step=1.183, eta=8:54:11\n",
      "2019-04-22 13:49:04 Iter 23000 [Train]: loss=67.32, epe=4.99, lr=0.000083, samples/sec=54.6, sec/step=1.172, eta=8:47:28\n",
      "2019-04-22 13:49:32 Iter 23000 [Val]: loss=76.07, epe=5.66\n",
      "Saving model...\n",
      "INFO:tensorflow:./pwcnet-sm-6-2-cyclic-chairsthingsmix-fp16/pwcnet.ckpt-23000 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "... model saved in ./pwcnet-sm-6-2-cyclic-chairsthingsmix-fp16/pwcnet.ckpt-23000\n",
      "2019-04-22 13:54:33 Iter 23100 [Train]: loss=64.19, epe=4.74, lr=0.000086, samples/sec=54.0, sec/step=1.185, eta=8:51:16\n",
      "2019-04-22 13:58:54 Iter 23200 [Train]: loss=82.08, epe=6.14, lr=0.000088, samples/sec=53.2, sec/step=1.203, eta=8:57:12\n",
      "2019-04-22 14:03:08 Iter 23300 [Train]: loss=66.03, epe=4.95, lr=0.000091, samples/sec=54.3, sec/step=1.179, eta=8:44:39\n",
      "2019-04-22 14:07:23 Iter 23400 [Train]: loss=67.24, epe=4.98, lr=0.000093, samples/sec=53.9, sec/step=1.188, eta=8:46:52\n",
      "2019-04-22 14:11:40 Iter 23500 [Train]: loss=101.67, epe=8.09, lr=0.000096, samples/sec=53.4, sec/step=1.198, eta=8:49:13\n",
      "2019-04-22 14:16:03 Iter 23600 [Train]: loss=65.35, epe=4.82, lr=0.000098, samples/sec=52.8, sec/step=1.211, eta=8:53:00\n",
      "2019-04-22 14:20:21 Iter 23700 [Train]: loss=62.53, epe=4.60, lr=0.000101, samples/sec=54.3, sec/step=1.179, eta=8:37:00\n",
      "2019-04-22 14:24:38 Iter 23800 [Train]: loss=76.67, epe=5.77, lr=0.000103, samples/sec=54.0, sec/step=1.185, eta=8:37:16\n",
      "2019-04-22 14:28:57 Iter 23900 [Train]: loss=70.11, epe=5.22, lr=0.000106, samples/sec=54.1, sec/step=1.183, eta=8:34:30\n",
      "2019-04-22 14:33:16 Iter 24000 [Train]: loss=67.06, epe=4.96, lr=0.000108, samples/sec=53.8, sec/step=1.189, eta=8:35:26\n",
      "2019-04-22 14:33:43 Iter 24000 [Val]: loss=69.38, epe=5.12\n",
      "Saving model...\n",
      "INFO:tensorflow:./pwcnet-sm-6-2-cyclic-chairsthingsmix-fp16/pwcnet.ckpt-24000 is not in all_model_checkpoint_paths. Manually adding it.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... model saved in ./pwcnet-sm-6-2-cyclic-chairsthingsmix-fp16/pwcnet.ckpt-24000\n",
      "2019-04-22 14:38:43 Iter 24100 [Train]: loss=64.82, epe=4.79, lr=0.000110, samples/sec=53.8, sec/step=1.191, eta=8:33:54\n",
      "2019-04-22 14:42:57 Iter 24200 [Train]: loss=66.23, epe=4.90, lr=0.000113, samples/sec=53.7, sec/step=1.192, eta=8:32:22\n",
      "2019-04-22 14:47:10 Iter 24300 [Train]: loss=74.66, epe=5.58, lr=0.000115, samples/sec=55.0, sec/step=1.164, eta=8:18:47\n",
      "2019-04-22 14:51:25 Iter 24400 [Train]: loss=110.92, epe=10.56, lr=0.000118, samples/sec=55.3, sec/step=1.158, eta=8:14:14\n",
      "2019-04-22 14:55:49 Iter 24500 [Train]: loss=72.76, epe=5.57, lr=0.000120, samples/sec=53.7, sec/step=1.191, eta=8:26:09\n",
      "2019-04-22 15:00:06 Iter 24600 [Train]: loss=65.84, epe=4.87, lr=0.000123, samples/sec=54.8, sec/step=1.167, eta=8:14:13\n",
      "2019-04-22 15:04:25 Iter 24700 [Train]: loss=63.60, epe=4.68, lr=0.000125, samples/sec=54.2, sec/step=1.181, eta=8:18:04\n",
      "2019-04-22 15:08:58 Iter 24800 [Train]: loss=66.07, epe=4.89, lr=0.000128, samples/sec=49.1, sec/step=1.304, eta=9:07:49\n",
      "2019-04-22 15:13:44 Iter 24900 [Train]: loss=101.12, epe=8.17, lr=0.000130, samples/sec=43.9, sec/step=1.458, eta=10:09:56\n",
      "2019-04-22 15:17:50 Iter 25000 [Train]: loss=80.59, epe=6.06, lr=0.000133, samples/sec=57.1, sec/step=1.122, eta=7:47:18\n",
      "2019-04-22 15:18:16 Iter 25000 [Val]: loss=85.27, epe=6.45\n",
      "Saving model...\n",
      "INFO:tensorflow:./pwcnet-sm-6-2-cyclic-chairsthingsmix-fp16/pwcnet.ckpt-25000 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "... model saved in ./pwcnet-sm-6-2-cyclic-chairsthingsmix-fp16/pwcnet.ckpt-25000\n",
      "2019-04-22 15:23:08 Iter 25100 [Train]: loss=64.90, epe=4.80, lr=0.000135, samples/sec=57.1, sec/step=1.121, eta=7:45:12\n",
      "2019-04-22 15:27:15 Iter 25200 [Train]: loss=65.66, epe=4.85, lr=0.000137, samples/sec=57.2, sec/step=1.119, eta=7:42:27\n",
      "2019-04-22 15:31:23 Iter 25300 [Train]: loss=66.68, epe=4.92, lr=0.000140, samples/sec=56.9, sec/step=1.124, eta=7:42:41\n",
      "2019-04-22 15:35:27 Iter 25400 [Train]: loss=94.23, epe=7.44, lr=0.000142, samples/sec=58.5, sec/step=1.093, eta=7:28:12\n",
      "2019-04-22 15:39:28 Iter 25500 [Train]: loss=65.95, epe=4.88, lr=0.000145, samples/sec=59.2, sec/step=1.081, eta=7:21:27\n",
      "2019-04-22 15:43:36 Iter 25600 [Train]: loss=67.06, epe=4.96, lr=0.000147, samples/sec=58.8, sec/step=1.089, eta=7:22:47\n",
      "2019-04-22 15:47:45 Iter 25700 [Train]: loss=92.79, epe=6.28, lr=0.000150, samples/sec=58.7, sec/step=1.091, eta=7:21:53\n",
      "2019-04-22 15:52:02 Iter 25800 [Train]: loss=67.70, epe=5.05, lr=0.000152, samples/sec=57.3, sec/step=1.117, eta=7:30:38\n",
      "2019-04-22 15:56:36 Iter 25900 [Train]: loss=71.40, epe=5.33, lr=0.000155, samples/sec=55.2, sec/step=1.160, eta=7:45:52\n",
      "2019-04-22 16:00:55 Iter 26000 [Train]: loss=63.99, epe=4.72, lr=0.000157, samples/sec=57.1, sec/step=1.122, eta=7:28:38\n",
      "2019-04-22 16:01:20 Iter 26000 [Val]: loss=74.20, epe=5.52\n",
      "Saving model...\n",
      "INFO:tensorflow:./pwcnet-sm-6-2-cyclic-chairsthingsmix-fp16/pwcnet.ckpt-26000 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "... model saved in ./pwcnet-sm-6-2-cyclic-chairsthingsmix-fp16/pwcnet.ckpt-26000\n",
      "2019-04-22 16:06:18 Iter 26100 [Train]: loss=65.43, epe=4.82, lr=0.000159, samples/sec=57.4, sec/step=1.116, eta=7:24:28\n",
      "2019-04-22 16:10:34 Iter 26200 [Train]: loss=132.44, epe=8.85, lr=0.000162, samples/sec=56.9, sec/step=1.125, eta=7:26:06\n",
      "2019-04-22 16:14:42 Iter 26300 [Train]: loss=63.45, epe=4.67, lr=0.000164, samples/sec=58.2, sec/step=1.099, eta=7:14:14\n",
      "2019-04-22 16:20:02 Iter 26400 [Train]: loss=63.33, epe=4.66, lr=0.000167, samples/sec=49.8, sec/step=1.285, eta=8:25:26\n",
      "2019-04-22 16:25:23 Iter 26500 [Train]: loss=66.59, epe=4.96, lr=0.000169, samples/sec=49.6, sec/step=1.290, eta=8:25:03\n",
      "2019-04-22 16:30:40 Iter 26600 [Train]: loss=65.39, epe=4.82, lr=0.000172, samples/sec=50.2, sec/step=1.275, eta=8:17:14\n",
      "2019-04-22 16:35:59 Iter 26700 [Train]: loss=65.42, epe=4.82, lr=0.000174, samples/sec=49.1, sec/step=1.303, eta=8:25:59\n",
      "2019-04-22 16:41:20 Iter 26800 [Train]: loss=75.57, epe=5.66, lr=0.000177, samples/sec=49.9, sec/step=1.283, eta=8:16:07\n",
      "2019-04-22 16:46:38 Iter 26900 [Train]: loss=73.57, epe=5.51, lr=0.000179, samples/sec=50.0, sec/step=1.281, eta=8:13:07\n",
      "2019-04-22 16:51:52 Iter 27000 [Train]: loss=89.82, epe=7.24, lr=0.000182, samples/sec=49.9, sec/step=1.283, eta=8:11:52\n",
      "2019-04-22 16:52:24 Iter 27000 [Val]: loss=76.61, epe=5.71\n",
      "Saving model...\n",
      "INFO:tensorflow:./pwcnet-sm-6-2-cyclic-chairsthingsmix-fp16/pwcnet.ckpt-27000 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "... model saved in ./pwcnet-sm-6-2-cyclic-chairsthingsmix-fp16/pwcnet.ckpt-27000\n",
      "2019-04-22 16:58:35 Iter 27100 [Train]: loss=64.99, epe=4.78, lr=0.000184, samples/sec=49.0, sec/step=1.305, eta=8:18:15\n",
      "2019-04-22 17:03:53 Iter 27200 [Train]: loss=68.90, epe=5.11, lr=0.000186, samples/sec=49.6, sec/step=1.290, eta=8:10:11\n",
      "2019-04-22 17:09:11 Iter 27300 [Train]: loss=65.79, epe=4.85, lr=0.000189, samples/sec=49.4, sec/step=1.296, eta=8:10:18\n",
      "2019-04-22 17:14:40 Iter 27400 [Train]: loss=69.77, epe=5.24, lr=0.000191, samples/sec=48.3, sec/step=1.326, eta=8:19:37\n",
      "2019-04-22 17:20:03 Iter 27500 [Train]: loss=69.54, epe=5.15, lr=0.000194, samples/sec=48.9, sec/step=1.309, eta=8:10:59\n",
      "2019-04-22 17:25:36 Iter 27600 [Train]: loss=78.66, epe=5.91, lr=0.000196, samples/sec=48.4, sec/step=1.321, eta=8:13:11\n",
      "2019-04-22 17:30:55 Iter 27700 [Train]: loss=90.75, epe=7.41, lr=0.000199, samples/sec=49.9, sec/step=1.283, eta=7:57:01\n",
      "2019-04-22 17:36:27 Iter 27800 [Train]: loss=63.01, epe=4.63, lr=0.000201, samples/sec=48.4, sec/step=1.322, eta=8:09:17\n",
      "2019-04-22 17:42:16 Iter 27900 [Train]: loss=69.77, epe=5.13, lr=0.000204, samples/sec=48.1, sec/step=1.331, eta=8:10:17\n",
      "2019-04-22 17:47:47 Iter 28000 [Train]: loss=70.37, epe=5.22, lr=0.000206, samples/sec=48.8, sec/step=1.310, eta=8:00:24\n",
      "2019-04-22 17:48:19 Iter 28000 [Val]: loss=75.40, epe=5.61\n",
      "Saving model...\n",
      "INFO:tensorflow:./pwcnet-sm-6-2-cyclic-chairsthingsmix-fp16/pwcnet.ckpt-28000 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "... model saved in ./pwcnet-sm-6-2-cyclic-chairsthingsmix-fp16/pwcnet.ckpt-28000\n",
      "2019-04-22 17:54:52 Iter 28100 [Train]: loss=111.61, epe=8.69, lr=0.000208, samples/sec=49.0, sec/step=1.306, eta=7:56:52\n",
      "2019-04-22 18:00:33 Iter 28200 [Train]: loss=67.96, epe=5.02, lr=0.000211, samples/sec=48.8, sec/step=1.313, eta=7:56:55\n",
      "2019-04-22 18:07:04 Iter 28300 [Train]: loss=63.33, epe=4.65, lr=0.000213, samples/sec=45.0, sec/step=1.421, eta=8:33:51\n",
      "2019-04-22 18:14:57 Iter 28400 [Train]: loss=66.86, epe=4.94, lr=0.000216, samples/sec=42.7, sec/step=1.500, eta=9:00:04\n",
      "2019-04-22 18:23:09 Iter 28500 [Train]: loss=105.66, epe=8.04, lr=0.000218, samples/sec=43.0, sec/step=1.489, eta=8:53:28\n",
      "2019-04-22 18:28:52 Iter 28600 [Train]: loss=76.26, epe=5.70, lr=0.000221, samples/sec=49.0, sec/step=1.306, eta=7:45:48\n",
      "2019-04-22 18:34:13 Iter 28700 [Train]: loss=63.59, epe=4.67, lr=0.000223, samples/sec=49.7, sec/step=1.288, eta=7:37:05\n",
      "2019-04-22 18:39:31 Iter 28800 [Train]: loss=66.73, epe=4.92, lr=0.000226, samples/sec=50.0, sec/step=1.281, eta=7:32:43\n",
      "2019-04-22 18:44:53 Iter 28900 [Train]: loss=69.31, epe=5.13, lr=0.000228, samples/sec=49.3, sec/step=1.298, eta=7:36:18\n",
      "2019-04-22 18:50:10 Iter 29000 [Train]: loss=65.47, epe=4.82, lr=0.000230, samples/sec=49.1, sec/step=1.302, eta=7:35:45\n",
      "2019-04-22 18:50:43 Iter 29000 [Val]: loss=75.05, epe=5.58\n",
      "Saving model...\n",
      "INFO:tensorflow:./pwcnet-sm-6-2-cyclic-chairsthingsmix-fp16/pwcnet.ckpt-29000 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "... model saved in ./pwcnet-sm-6-2-cyclic-chairsthingsmix-fp16/pwcnet.ckpt-29000\n",
      "2019-04-22 18:56:53 Iter 29100 [Train]: loss=71.38, epe=5.28, lr=0.000233, samples/sec=49.7, sec/step=1.289, eta=7:28:59\n",
      "2019-04-22 19:02:13 Iter 29200 [Train]: loss=66.96, epe=4.95, lr=0.000235, samples/sec=50.2, sec/step=1.276, eta=7:22:21\n",
      "2019-04-22 19:07:30 Iter 29300 [Train]: loss=82.75, epe=6.25, lr=0.000238, samples/sec=50.2, sec/step=1.275, eta=7:19:46\n",
      "2019-04-22 19:12:52 Iter 29400 [Train]: loss=65.73, epe=4.84, lr=0.000240, samples/sec=49.4, sec/step=1.296, eta=7:25:04\n",
      "2019-04-22 19:18:15 Iter 29500 [Train]: loss=64.43, epe=4.73, lr=0.000243, samples/sec=49.3, sec/step=1.298, eta=7:23:37\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-04-22 19:23:33 Iter 29600 [Train]: loss=173.64, epe=9.39, lr=0.000245, samples/sec=50.4, sec/step=1.270, eta=7:11:41\n",
      "2019-04-22 19:28:55 Iter 29700 [Train]: loss=66.28, epe=4.89, lr=0.000248, samples/sec=49.6, sec/step=1.291, eta=7:16:54\n",
      "2019-04-22 19:34:13 Iter 29800 [Train]: loss=72.86, epe=5.55, lr=0.000250, samples/sec=49.9, sec/step=1.283, eta=7:12:05\n",
      "2019-04-22 19:39:32 Iter 29900 [Train]: loss=93.07, epe=8.08, lr=0.000253, samples/sec=49.6, sec/step=1.290, eta=7:12:18\n",
      "2019-04-22 19:44:52 Iter 30000 [Train]: loss=67.73, epe=5.01, lr=0.000255, samples/sec=49.7, sec/step=1.287, eta=7:09:00\n",
      "2019-04-22 19:45:25 Iter 30000 [Val]: loss=74.01, epe=5.49\n",
      "Saving model...\n",
      "INFO:tensorflow:./pwcnet-sm-6-2-cyclic-chairsthingsmix-fp16/pwcnet.ckpt-30000 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "... model saved in ./pwcnet-sm-6-2-cyclic-chairsthingsmix-fp16/pwcnet.ckpt-30000\n",
      "2019-04-22 19:51:36 Iter 30100 [Train]: loss=66.65, epe=4.97, lr=0.000253, samples/sec=49.6, sec/step=1.290, eta=7:07:47\n",
      "2019-04-22 19:57:01 Iter 30200 [Train]: loss=76.23, epe=5.70, lr=0.000250, samples/sec=48.7, sec/step=1.314, eta=7:13:32\n",
      "2019-04-22 20:02:23 Iter 30300 [Train]: loss=65.57, epe=4.82, lr=0.000248, samples/sec=49.4, sec/step=1.295, eta=7:05:15\n",
      "2019-04-22 20:07:47 Iter 30400 [Train]: loss=68.33, epe=5.10, lr=0.000245, samples/sec=49.2, sec/step=1.301, eta=7:05:01\n",
      "2019-04-22 20:13:05 Iter 30500 [Train]: loss=72.98, epe=5.40, lr=0.000243, samples/sec=49.5, sec/step=1.292, eta=7:00:00\n",
      "2019-04-22 20:18:27 Iter 30600 [Train]: loss=77.84, epe=5.84, lr=0.000240, samples/sec=49.4, sec/step=1.294, eta=6:58:31\n",
      "2019-04-22 20:23:49 Iter 30700 [Train]: loss=62.11, epe=4.54, lr=0.000238, samples/sec=49.7, sec/step=1.287, eta=6:54:08\n",
      "2019-04-22 20:29:05 Iter 30800 [Train]: loss=70.47, epe=5.26, lr=0.000235, samples/sec=50.4, sec/step=1.269, eta=6:46:13\n",
      "2019-04-22 20:34:29 Iter 30900 [Train]: loss=97.80, epe=nan, lr=0.000233, samples/sec=49.1, sec/step=1.303, eta=6:54:43\n",
      "2019-04-22 20:39:51 Iter 31000 [Train]: loss=65.46, epe=4.81, lr=0.000231, samples/sec=49.6, sec/step=1.291, eta=6:48:57\n",
      "2019-04-22 20:40:25 Iter 31000 [Val]: loss=75.38, epe=5.60\n",
      "Saving model...\n",
      "INFO:tensorflow:./pwcnet-sm-6-2-cyclic-chairsthingsmix-fp16/pwcnet.ckpt-31000 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "... model saved in ./pwcnet-sm-6-2-cyclic-chairsthingsmix-fp16/pwcnet.ckpt-31000\n",
      "2019-04-22 20:46:43 Iter 31100 [Train]: loss=63.21, epe=4.62, lr=0.000228, samples/sec=49.8, sec/step=1.284, eta=6:44:37\n",
      "2019-04-22 20:52:01 Iter 31200 [Train]: loss=68.87, epe=5.32, lr=0.000226, samples/sec=49.7, sec/step=1.288, eta=6:43:39\n",
      "2019-04-22 20:57:21 Iter 31300 [Train]: loss=120.25, epe=9.53, lr=0.000223, samples/sec=49.6, sec/step=1.289, eta=6:41:51\n",
      "2019-04-22 21:02:41 Iter 31400 [Train]: loss=75.49, epe=5.64, lr=0.000221, samples/sec=49.7, sec/step=1.287, eta=6:38:53\n",
      "2019-04-22 21:08:01 Iter 31500 [Train]: loss=62.79, epe=4.60, lr=0.000218, samples/sec=49.2, sec/step=1.302, eta=6:41:19\n",
      "2019-04-22 21:13:21 Iter 31600 [Train]: loss=64.80, epe=4.77, lr=0.000216, samples/sec=49.7, sec/step=1.288, eta=6:34:55\n",
      "2019-04-22 21:18:44 Iter 31700 [Train]: loss=66.13, epe=4.88, lr=0.000213, samples/sec=49.0, sec/step=1.307, eta=6:38:36\n",
      "2019-04-22 21:24:03 Iter 31800 [Train]: loss=64.89, epe=4.79, lr=0.000211, samples/sec=49.8, sec/step=1.285, eta=6:29:50\n",
      "2019-04-22 21:29:24 Iter 31900 [Train]: loss=90.32, epe=8.09, lr=0.000208, samples/sec=50.1, sec/step=1.278, eta=6:25:40\n",
      "2019-04-22 21:34:46 Iter 32000 [Train]: loss=62.96, epe=4.63, lr=0.000206, samples/sec=49.3, sec/step=1.298, eta=6:29:27\n",
      "2019-04-22 21:35:19 Iter 32000 [Val]: loss=76.11, epe=5.66\n",
      "Saving model...\n",
      "INFO:tensorflow:./pwcnet-sm-6-2-cyclic-chairsthingsmix-fp16/pwcnet.ckpt-32000 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "... model saved in ./pwcnet-sm-6-2-cyclic-chairsthingsmix-fp16/pwcnet.ckpt-32000\n",
      "2019-04-22 21:41:28 Iter 32100 [Train]: loss=67.14, epe=4.91, lr=0.000204, samples/sec=49.7, sec/step=1.287, eta=6:23:48\n",
      "2019-04-22 21:46:49 Iter 32200 [Train]: loss=75.57, epe=5.65, lr=0.000201, samples/sec=49.4, sec/step=1.295, eta=6:24:09\n",
      "2019-04-22 21:52:11 Iter 32300 [Train]: loss=68.00, epe=5.03, lr=0.000199, samples/sec=48.9, sec/step=1.308, eta=6:26:00\n",
      "2019-04-22 21:57:32 Iter 32400 [Train]: loss=65.33, epe=4.82, lr=0.000196, samples/sec=49.7, sec/step=1.287, eta=6:17:31\n",
      "2019-04-22 22:02:51 Iter 32500 [Train]: loss=62.18, epe=4.55, lr=0.000194, samples/sec=49.0, sec/step=1.306, eta=6:21:00\n",
      "2019-04-22 22:08:15 Iter 32600 [Train]: loss=66.26, epe=4.89, lr=0.000191, samples/sec=49.1, sec/step=1.303, eta=6:18:00\n",
      "2019-04-22 22:13:35 Iter 32700 [Train]: loss=75.03, epe=5.61, lr=0.000189, samples/sec=48.8, sec/step=1.311, eta=6:18:07\n",
      "2019-04-22 22:18:56 Iter 32800 [Train]: loss=64.42, epe=4.77, lr=0.000186, samples/sec=49.3, sec/step=1.298, eta=6:11:58\n",
      "2019-04-22 22:24:15 Iter 32900 [Train]: loss=63.97, epe=4.74, lr=0.000184, samples/sec=49.1, sec/step=1.302, eta=6:11:07\n",
      "2019-04-22 22:29:32 Iter 33000 [Train]: loss=83.44, epe=6.88, lr=0.000182, samples/sec=49.4, sec/step=1.296, eta=6:07:20\n",
      "2019-04-22 22:30:05 Iter 33000 [Val]: loss=72.32, epe=5.38\n",
      "Saving model...\n",
      "INFO:tensorflow:./pwcnet-sm-6-2-cyclic-chairsthingsmix-fp16/pwcnet.ckpt-33000 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "... model saved in ./pwcnet-sm-6-2-cyclic-chairsthingsmix-fp16/pwcnet.ckpt-33000\n",
      "2019-04-22 22:36:16 Iter 33100 [Train]: loss=58.75, epe=4.29, lr=0.000179, samples/sec=49.4, sec/step=1.295, eta=6:04:51\n",
      "2019-04-22 22:41:37 Iter 33200 [Train]: loss=61.39, epe=4.50, lr=0.000177, samples/sec=49.8, sec/step=1.285, eta=5:59:45\n",
      "2019-04-22 22:47:01 Iter 33300 [Train]: loss=62.39, epe=4.57, lr=0.000174, samples/sec=50.0, sec/step=1.281, eta=5:56:25\n",
      "2019-04-22 22:52:20 Iter 33400 [Train]: loss=67.99, epe=5.06, lr=0.000172, samples/sec=50.1, sec/step=1.276, eta=5:53:05\n",
      "2019-04-22 22:57:41 Iter 33500 [Train]: loss=61.22, epe=4.48, lr=0.000169, samples/sec=49.9, sec/step=1.282, eta=5:52:38\n",
      "2019-04-22 23:03:02 Iter 33600 [Train]: loss=61.64, epe=4.51, lr=0.000167, samples/sec=49.8, sec/step=1.286, eta=5:51:29\n",
      "2019-04-22 23:08:31 Iter 33700 [Train]: loss=113.88, epe=8.71, lr=0.000164, samples/sec=49.5, sec/step=1.292, eta=5:51:00\n",
      "2019-04-22 23:14:31 Iter 33800 [Train]: loss=59.55, epe=4.34, lr=0.000162, samples/sec=46.9, sec/step=1.365, eta=6:08:26\n",
      "2019-04-22 23:20:21 Iter 33900 [Train]: loss=71.95, epe=5.38, lr=0.000159, samples/sec=48.8, sec/step=1.312, eta=5:51:58\n",
      "2019-04-22 23:30:16 Iter 34000 [Train]: loss=64.93, epe=4.79, lr=0.000157, samples/sec=38.8, sec/step=1.647, eta=7:19:18\n",
      "2019-04-22 23:31:13 Iter 34000 [Val]: loss=63.37, epe=4.62\n",
      "Saving model...\n",
      "INFO:tensorflow:./pwcnet-sm-6-2-cyclic-chairsthingsmix-fp16/pwcnet.ckpt-34000 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "... model saved in ./pwcnet-sm-6-2-cyclic-chairsthingsmix-fp16/pwcnet.ckpt-34000\n",
      "2019-04-22 23:43:18 Iter 34100 [Train]: loss=59.84, epe=4.37, lr=0.000155, samples/sec=36.5, sec/step=1.755, eta=7:45:11\n",
      "2019-04-22 23:53:39 Iter 34200 [Train]: loss=59.67, epe=4.35, lr=0.000152, samples/sec=36.3, sec/step=1.765, eta=7:44:47\n",
      "2019-04-23 00:04:16 Iter 34300 [Train]: loss=85.87, epe=7.29, lr=0.000150, samples/sec=36.3, sec/step=1.763, eta=7:41:26\n",
      "2019-04-23 00:14:55 Iter 34400 [Train]: loss=89.26, epe=7.43, lr=0.000147, samples/sec=36.2, sec/step=1.769, eta=7:40:02\n",
      "2019-04-23 00:25:26 Iter 34500 [Train]: loss=59.97, epe=4.37, lr=0.000145, samples/sec=35.9, sec/step=1.783, eta=7:40:35\n",
      "2019-04-23 00:36:05 Iter 34600 [Train]: loss=60.96, epe=4.46, lr=0.000142, samples/sec=35.4, sec/step=1.808, eta=7:43:59\n",
      "2019-04-23 00:46:47 Iter 34700 [Train]: loss=63.17, epe=4.65, lr=0.000140, samples/sec=36.3, sec/step=1.765, eta=7:30:05\n",
      "2019-04-23 00:57:10 Iter 34800 [Train]: loss=76.71, epe=5.75, lr=0.000137, samples/sec=37.5, sec/step=1.709, eta=7:12:54\n",
      "2019-04-23 01:07:34 Iter 34900 [Train]: loss=65.29, epe=4.83, lr=0.000135, samples/sec=38.1, sec/step=1.681, eta=7:03:05\n",
      "2019-04-23 01:18:12 Iter 35000 [Train]: loss=59.24, epe=4.33, lr=0.000133, samples/sec=36.9, sec/step=1.737, eta=7:14:10\n",
      "2019-04-23 01:19:09 Iter 35000 [Val]: loss=77.89, epe=5.85\n",
      "Saving model...\n",
      "INFO:tensorflow:./pwcnet-sm-6-2-cyclic-chairsthingsmix-fp16/pwcnet.ckpt-35000 is not in all_model_checkpoint_paths. Manually adding it.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... model saved in ./pwcnet-sm-6-2-cyclic-chairsthingsmix-fp16/pwcnet.ckpt-35000\n",
      "2019-04-23 01:31:02 Iter 35100 [Train]: loss=73.25, epe=5.49, lr=0.000130, samples/sec=37.3, sec/step=1.715, eta=7:05:48\n",
      "2019-04-23 01:41:51 Iter 35200 [Train]: loss=58.43, epe=4.25, lr=0.000128, samples/sec=33.3, sec/step=1.919, eta=7:53:27\n",
      "2019-04-23 01:52:38 Iter 35300 [Train]: loss=94.67, epe=7.25, lr=0.000125, samples/sec=35.1, sec/step=1.823, eta=7:26:35\n",
      "2019-04-23 02:03:23 Iter 35400 [Train]: loss=57.81, epe=4.21, lr=0.000123, samples/sec=36.0, sec/step=1.780, eta=7:13:08\n",
      "2019-04-23 02:14:15 Iter 35500 [Train]: loss=59.61, epe=4.35, lr=0.000120, samples/sec=36.9, sec/step=1.732, eta=6:58:36\n",
      "2019-04-23 02:25:09 Iter 35600 [Train]: loss=59.82, epe=4.37, lr=0.000118, samples/sec=35.6, sec/step=1.800, eta=7:12:00\n",
      "2019-04-23 02:35:43 Iter 35700 [Train]: loss=64.34, epe=4.86, lr=0.000115, samples/sec=35.8, sec/step=1.790, eta=7:06:39\n",
      "2019-04-23 02:46:23 Iter 35800 [Train]: loss=55.64, epe=4.03, lr=0.000113, samples/sec=36.9, sec/step=1.736, eta=6:50:54\n",
      "2019-04-23 02:57:07 Iter 35900 [Train]: loss=62.04, epe=4.60, lr=0.000110, samples/sec=35.6, sec/step=1.796, eta=7:01:58\n",
      "2019-04-23 03:07:50 Iter 36000 [Train]: loss=95.90, epe=7.02, lr=0.000108, samples/sec=36.9, sec/step=1.733, eta=6:44:18\n",
      "2019-04-23 03:08:48 Iter 36000 [Val]: loss=69.24, epe=5.12\n",
      "Saving model...\n",
      "INFO:tensorflow:./pwcnet-sm-6-2-cyclic-chairsthingsmix-fp16/pwcnet.ckpt-36000 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "... model saved in ./pwcnet-sm-6-2-cyclic-chairsthingsmix-fp16/pwcnet.ckpt-36000\n",
      "2019-04-23 03:21:08 Iter 36100 [Train]: loss=60.98, epe=4.37, lr=0.000106, samples/sec=33.4, sec/step=1.917, eta=7:24:08\n",
      "2019-04-23 03:31:43 Iter 36200 [Train]: loss=69.06, epe=5.14, lr=0.000103, samples/sec=34.3, sec/step=1.866, eta=7:09:05\n",
      "2019-04-23 03:42:44 Iter 36300 [Train]: loss=60.38, epe=4.42, lr=0.000101, samples/sec=35.1, sec/step=1.825, eta=6:56:49\n",
      "2019-04-23 03:53:32 Iter 36400 [Train]: loss=58.60, epe=4.28, lr=0.000098, samples/sec=35.7, sec/step=1.794, eta=6:46:40\n",
      "2019-04-23 04:04:15 Iter 36500 [Train]: loss=58.79, epe=4.30, lr=0.000096, samples/sec=37.2, sec/step=1.718, eta=6:26:36\n",
      "2019-04-23 04:15:02 Iter 36600 [Train]: loss=59.88, epe=4.43, lr=0.000093, samples/sec=36.0, sec/step=1.776, eta=6:36:44\n",
      "2019-04-23 04:25:59 Iter 36700 [Train]: loss=131.89, epe=11.38, lr=0.000091, samples/sec=36.5, sec/step=1.753, eta=6:28:35\n",
      "2019-04-23 04:36:52 Iter 36800 [Train]: loss=60.22, epe=4.41, lr=0.000088, samples/sec=34.7, sec/step=1.845, eta=6:45:58\n",
      "2019-04-23 04:47:53 Iter 36900 [Train]: loss=56.87, epe=4.14, lr=0.000086, samples/sec=36.4, sec/step=1.760, eta=6:24:14\n",
      "2019-04-23 04:59:01 Iter 37000 [Train]: loss=83.72, epe=6.82, lr=0.000084, samples/sec=35.1, sec/step=1.826, eta=6:35:35\n",
      "2019-04-23 05:00:03 Iter 37000 [Val]: loss=63.75, epe=4.65\n",
      "Saving model...\n",
      "INFO:tensorflow:./pwcnet-sm-6-2-cyclic-chairsthingsmix-fp16/pwcnet.ckpt-37000 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "... model saved in ./pwcnet-sm-6-2-cyclic-chairsthingsmix-fp16/pwcnet.ckpt-37000\n",
      "2019-04-23 05:12:21 Iter 37100 [Train]: loss=57.38, epe=nan, lr=0.000081, samples/sec=37.2, sec/step=1.719, eta=6:09:31\n",
      "2019-04-23 05:23:23 Iter 37200 [Train]: loss=58.14, epe=4.24, lr=0.000079, samples/sec=37.3, sec/step=1.717, eta=6:06:12\n",
      "2019-04-23 05:34:08 Iter 37300 [Train]: loss=68.64, epe=nan, lr=0.000076, samples/sec=37.0, sec/step=1.728, eta=6:05:50\n",
      "2019-04-23 05:44:46 Iter 37400 [Train]: loss=59.61, epe=4.36, lr=0.000074, samples/sec=35.6, sec/step=1.797, eta=6:17:26\n",
      "2019-04-23 05:55:43 Iter 37500 [Train]: loss=59.73, epe=4.32, lr=0.000071, samples/sec=35.9, sec/step=1.781, eta=6:11:06\n",
      "2019-04-23 06:06:17 Iter 37600 [Train]: loss=58.35, epe=4.26, lr=0.000069, samples/sec=36.0, sec/step=1.779, eta=6:07:41\n",
      "2019-04-23 06:17:00 Iter 37700 [Train]: loss=59.25, epe=4.37, lr=0.000066, samples/sec=36.7, sec/step=1.743, eta=5:57:15\n",
      "2019-04-23 06:27:59 Iter 37800 [Train]: loss=73.21, epe=5.47, lr=0.000064, samples/sec=34.8, sec/step=1.840, eta=6:14:10\n",
      "2019-04-23 06:38:40 Iter 37900 [Train]: loss=56.49, epe=4.10, lr=0.000061, samples/sec=35.0, sec/step=1.827, eta=6:08:31\n",
      "2019-04-23 06:49:35 Iter 38000 [Train]: loss=60.17, epe=4.49, lr=0.000059, samples/sec=35.5, sec/step=1.803, eta=6:00:38\n",
      "2019-04-23 06:50:32 Iter 38000 [Val]: loss=70.81, epe=5.24\n",
      "Saving model...\n",
      "INFO:tensorflow:./pwcnet-sm-6-2-cyclic-chairsthingsmix-fp16/pwcnet.ckpt-38000 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "... model saved in ./pwcnet-sm-6-2-cyclic-chairsthingsmix-fp16/pwcnet.ckpt-38000\n",
      "2019-04-23 07:02:50 Iter 38100 [Train]: loss=103.08, epe=8.82, lr=0.000057, samples/sec=35.6, sec/step=1.799, eta=5:56:52\n",
      "2019-04-23 07:13:46 Iter 38200 [Train]: loss=54.71, epe=3.97, lr=0.000054, samples/sec=35.9, sec/step=1.782, eta=5:50:22\n",
      "2019-04-23 07:24:33 Iter 38300 [Train]: loss=56.72, epe=4.13, lr=0.000052, samples/sec=36.4, sec/step=1.759, eta=5:42:57\n",
      "2019-04-23 07:35:40 Iter 38400 [Train]: loss=58.59, epe=4.41, lr=0.000049, samples/sec=36.3, sec/step=1.764, eta=5:41:04\n",
      "2019-04-23 07:46:54 Iter 38500 [Train]: loss=54.74, epe=3.97, lr=0.000047, samples/sec=34.0, sec/step=1.880, eta=6:00:19\n",
      "2019-04-23 07:58:02 Iter 38600 [Train]: loss=52.77, epe=3.81, lr=0.000044, samples/sec=35.8, sec/step=1.786, eta=5:39:25\n",
      "2019-04-23 08:09:09 Iter 38700 [Train]: loss=84.85, epe=7.03, lr=0.000042, samples/sec=34.8, sec/step=1.837, eta=5:46:01\n",
      "2019-04-23 08:20:06 Iter 38800 [Train]: loss=71.95, epe=5.44, lr=0.000039, samples/sec=35.8, sec/step=1.789, eta=5:33:55\n",
      "2019-04-23 08:31:17 Iter 38900 [Train]: loss=54.62, epe=3.96, lr=0.000037, samples/sec=35.2, sec/step=1.819, eta=5:36:31\n",
      "2019-04-23 08:42:01 Iter 39000 [Train]: loss=57.16, epe=4.16, lr=0.000035, samples/sec=36.3, sec/step=1.761, eta=5:22:55\n",
      "2019-04-23 08:43:06 Iter 39000 [Val]: loss=63.43, epe=4.64\n",
      "Saving model...\n",
      "INFO:tensorflow:./pwcnet-sm-6-2-cyclic-chairsthingsmix-fp16/pwcnet.ckpt-39000 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "... model saved in ./pwcnet-sm-6-2-cyclic-chairsthingsmix-fp16/pwcnet.ckpt-39000\n",
      "2019-04-23 08:55:44 Iter 39100 [Train]: loss=64.57, epe=4.78, lr=0.000032, samples/sec=35.4, sec/step=1.808, eta=5:28:28\n",
      "2019-04-23 09:06:44 Iter 39200 [Train]: loss=58.72, epe=4.40, lr=0.000030, samples/sec=35.1, sec/step=1.822, eta=5:27:57\n",
      "2019-04-23 09:17:49 Iter 39300 [Train]: loss=54.62, epe=3.96, lr=0.000027, samples/sec=33.9, sec/step=1.885, eta=5:36:13\n",
      "2019-04-23 09:28:55 Iter 39400 [Train]: loss=91.90, epe=7.82, lr=0.000025, samples/sec=34.9, sec/step=1.834, eta=5:24:02\n",
      "2019-04-23 09:40:02 Iter 39500 [Train]: loss=54.99, epe=3.99, lr=0.000022, samples/sec=33.7, sec/step=1.897, eta=5:31:55\n",
      "2019-04-23 09:51:05 Iter 39600 [Train]: loss=55.98, epe=4.06, lr=0.000020, samples/sec=35.4, sec/step=1.809, eta=5:13:32\n",
      "2019-04-23 10:02:14 Iter 39700 [Train]: loss=90.00, epe=7.38, lr=0.000017, samples/sec=35.0, sec/step=1.831, eta=5:14:19\n",
      "2019-04-23 10:13:25 Iter 39800 [Train]: loss=55.06, epe=nan, lr=0.000015, samples/sec=34.7, sec/step=1.843, eta=5:13:20\n",
      "2019-04-23 10:24:33 Iter 39900 [Train]: loss=54.39, epe=3.95, lr=0.000012, samples/sec=35.9, sec/step=1.781, eta=4:59:53\n",
      "2019-04-23 10:35:41 Iter 40000 [Train]: loss=54.59, epe=3.96, lr=0.000010, samples/sec=36.9, sec/step=1.735, eta=4:49:08\n",
      "2019-04-23 10:36:36 Iter 40000 [Val]: loss=61.42, epe=4.48\n",
      "Saving model...\n",
      "INFO:tensorflow:./pwcnet-sm-6-2-cyclic-chairsthingsmix-fp16/pwcnet.ckpt-40000 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "... model saved in ./pwcnet-sm-6-2-cyclic-chairsthingsmix-fp16/pwcnet.ckpt-40000\n",
      "2019-04-23 10:49:21 Iter 40100 [Train]: loss=54.74, epe=3.97, lr=0.000011, samples/sec=36.7, sec/step=1.745, eta=4:48:00\n",
      "2019-04-23 11:00:25 Iter 40200 [Train]: loss=65.23, epe=4.82, lr=0.000012, samples/sec=36.4, sec/step=1.760, eta=4:47:25\n",
      "2019-04-23 11:11:31 Iter 40300 [Train]: loss=78.17, epe=6.28, lr=0.000014, samples/sec=36.5, sec/step=1.751, eta=4:43:09\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-b1d44099aeaf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/tfoptflow/tfoptflow/model_pwcnet.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    649\u001b[0m                 \u001b[0mfeed_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx_tnsr\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx_adapt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my_tnsr\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0my_adapt\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    650\u001b[0m                 \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 651\u001b[0;31m                 \u001b[0my_hat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my_hat_train_tnsr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    652\u001b[0m                 \u001b[0mduration\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    653\u001b[0m                 \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpostproc_y_hat_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_hat\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# y_hat: [107.0802, 5.8556495, None]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1150\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1152\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1153\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1328\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1329\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1332\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1333\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1334\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1335\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1336\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1317\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1319\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1405\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1409\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "nn.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are the training curves for the run above:\n",
    "\n",
    "![](img/pwcnet-sm-6-2-cyclic-chairsthingsmix-fp16/loss.png)\n",
    "![](img/pwcnet-sm-6-2-cyclic-chairsthingsmix-fp16/epe.png)\n",
    "![](img/pwcnet-sm-6-2-cyclic-chairsthingsmix-fp16/lr.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
