{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PWC-Net-small model finetuning (with cyclical learning rate schedule)\n",
    "=======================================================\n",
    "\n",
    "In this notebook we:\n",
    "- Use a small model (no dense or residual connections), 6 level pyramid, uspample level 2 by 4 as the final flow prediction\n",
    "- Train the PWC-Net-small model on a mix of the `FlyingChairs` and `FlyingThings3DHalfRes` dataset using a Cyclic<sub>short</sub> schedule of our own\n",
    "- Let the Cyclic<sub>short</sub> schedule oscillate between `2e-05` and `1e-06` for 200,000 steps\n",
    "- Switch to the \"robust\" loss described in the paper, instead of the \"multiscale\" loss used during training\n",
    "\n",
    "Below, look for `TODO` references and customize this notebook based on your own needs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reference\n",
    "\n",
    "[2018a]<a name=\"2018a\"></a> Sun et al. 2018. PWC-Net: CNNs for Optical Flow Using Pyramid, Warping, and Cost Volume. [[arXiv]](https://arxiv.org/abs/1709.02371) [[web]](http://research.nvidia.com/publication/2018-02_PWC-Net%3A-CNNs-for) [[PyTorch (Official)]](https://github.com/NVlabs/PWC-Net/tree/master/PyTorch) [[Caffe (Official)]](https://github.com/NVlabs/PWC-Net/tree/master/Caffe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/Vol0/user/f.konokhov/miniconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3267, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-2-788693d64ca1>\", line 17, in <module>\n",
      "    from dataset_mpisintel import MPISintelDataset\n",
      "  File \"/Vol0/user/f.konokhov/tfoptflow/tfoptflow/dataset_mpisintel.py\", line 13, in <module>\n",
      "    from sklearn.model_selection import train_test_split\n",
      "  File \"/Vol0/user/f.konokhov/miniconda3/lib/python3.6/site-packages/sklearn/model_selection/__init__.py\", line 19, in <module>\n",
      "    from ._validation import cross_val_score\n",
      "  File \"/Vol0/user/f.konokhov/miniconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\", line 31, in <module>\n",
      "    from ..metrics.scorer import check_scoring, _check_multimetric_scoring\n",
      "  File \"/Vol0/user/f.konokhov/miniconda3/lib/python3.6/site-packages/sklearn/metrics/__init__.py\", line 7, in <module>\n",
      "    from .ranking import auc\n",
      "  File \"/Vol0/user/f.konokhov/miniconda3/lib/python3.6/site-packages/sklearn/metrics/ranking.py\", line 36, in <module>\n",
      "    from ..preprocessing import label_binarize\n",
      "  File \"/Vol0/user/f.konokhov/miniconda3/lib/python3.6/site-packages/sklearn/preprocessing/__init__.py\", line 6, in <module>\n",
      "    from ._function_transformer import FunctionTransformer\n",
      "  File \"/Vol0/user/f.konokhov/miniconda3/lib/python3.6/site-packages/sklearn/preprocessing/_function_transformer.py\", line 5, in <module>\n",
      "    from ..utils.testing import assert_allclose_dense_sparse\n",
      "  File \"/Vol0/user/f.konokhov/miniconda3/lib/python3.6/site-packages/sklearn/utils/testing.py\", line 21, in <module>\n",
      "    import scipy.io\n",
      "  File \"/Vol0/user/f.konokhov/miniconda3/lib/python3.6/site-packages/scipy/io/__init__.py\", line 97, in <module>\n",
      "    from .matlab import loadmat, savemat, whosmat, byteordercodes\n",
      "  File \"/Vol0/user/f.konokhov/miniconda3/lib/python3.6/site-packages/scipy/io/matlab/__init__.py\", line 13, in <module>\n",
      "    from .mio import loadmat, savemat, whosmat\n",
      "  File \"/Vol0/user/f.konokhov/miniconda3/lib/python3.6/site-packages/scipy/io/matlab/mio.py\", line 12, in <module>\n",
      "    from .mio5 import MatFile5Reader, MatFile5Writer\n",
      "  File \"/Vol0/user/f.konokhov/miniconda3/lib/python3.6/site-packages/scipy/io/matlab/mio5.py\", line 98, in <module>\n",
      "    from .mio5_utils import VarReader5\n",
      "  File \"mio5_utils.pyx\", line 67, in init scipy.io.matlab.mio5_utils\n",
      "  File \"<frozen importlib._bootstrap>\", line 971, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 955, in _find_and_load_unlocked\n",
      "  File \"<frozen importlib._bootstrap>\", line 665, in _load_unlocked\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 674, in exec_module\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 764, in get_code\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 833, in get_data\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Vol0/user/f.konokhov/miniconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2018, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Vol0/user/f.konokhov/miniconda3/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 1095, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/Vol0/user/f.konokhov/miniconda3/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 313, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/Vol0/user/f.konokhov/miniconda3/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 347, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/Vol0/user/f.konokhov/miniconda3/lib/python3.6/inspect.py\", line 1490, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/Vol0/user/f.konokhov/miniconda3/lib/python3.6/inspect.py\", line 1448, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/Vol0/user/f.konokhov/miniconda3/lib/python3.6/inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/Vol0/user/f.konokhov/miniconda3/lib/python3.6/inspect.py\", line 739, in getmodule\n",
      "    f = getabsfile(module)\n",
      "  File \"/Vol0/user/f.konokhov/miniconda3/lib/python3.6/inspect.py\", line 708, in getabsfile\n",
      "    _filename = getsourcefile(object) or getfile(object)\n",
      "  File \"/Vol0/user/f.konokhov/miniconda3/lib/python3.6/inspect.py\", line 693, in getsourcefile\n",
      "    if os.path.exists(filename):\n",
      "  File \"/Vol0/user/f.konokhov/miniconda3/lib/python3.6/genericpath.py\", line 19, in exists\n",
      "    os.stat(path)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "pwcnet_finetune.ipynb\n",
    "\n",
    "PWC-Net model finetuning.\n",
    "\n",
    "Written by Phil Ferriere\n",
    "\n",
    "Licensed under the MIT License (see LICENSE for details)\n",
    "\n",
    "Tensorboard:\n",
    "    [win] tensorboard --logdir=E:\\\\repos\\\\tf-optflow\\\\tfoptflow\\\\pwcnet-sm-6-2-cyclic-chairsthingsmix_finetuned\n",
    "    [ubu] tensorboard --logdir=/media/EDrive/repos/tf-optflow/tfoptflow/pwcnet-sm-6-2-cyclic-chairsthingsmix_finetuned\n",
    "\"\"\"\n",
    "from __future__ import absolute_import, division, print_function\n",
    "import sys\n",
    "from copy import deepcopy\n",
    "from dataset_mpisintel import MPISintelDataset\n",
    "from dataset_base import _DEFAULT_DS_TUNE_OPTIONS\n",
    "from dataset_flyingchairs import FlyingChairsDataset\n",
    "from dataset_flyingthings3d import FlyingThings3DHalfResDataset\n",
    "from dataset_kitti import KITTIDataset\n",
    "from dataset_mixer import MixedDataset\n",
    "from model_pwcnet import ModelPWCNet, _DEFAULT_PWCNET_FINETUNE_OPTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO: Set this first!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: You MUST set dataset_root to the correct path on your machine!\n",
    "if sys.platform.startswith(\"win\"):\n",
    "    _DATASET_ROOT = 'E:/datasets/'\n",
    "else:\n",
    "    _DATASET_ROOT = '/Vol1/dbstore/datasets/KITTI_odometry_2012/dataset/flow_train/' #'/Vol1/dbstore/datasets/sintel/'\n",
    "\n",
    "    \n",
    "# TODO: You MUST adjust the settings below based on the number of GPU(s) used for training\n",
    "# Set controller device and devices\n",
    "# A one-gpu setup would be something like controller='/device:GPU:0' and gpu_devices=['/device:GPU:0']\n",
    "# Here, we use a dual-GPU setup, as shown below\n",
    "# gpu_devices = ['/device:GPU:0', '/device:GPU:1']\n",
    "# controller = '/device:CPU:0'\n",
    "gpu_devices = ['/device:GPU:1']\n",
    "controller = '/device:GPU:1'\n",
    "\n",
    "# TODO: You MUST adjust this setting below based on the amount of memory on your GPU(s)\n",
    "# Batch size\n",
    "batch_size = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finetune on `sintel` mix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: You MUST set the batch size based on the capabilities of your GPU(s) \n",
    "#  Load train dataset\n",
    "ds_opts = deepcopy(_DEFAULT_DS_TUNE_OPTIONS)\n",
    "ds_opts['in_memory'] = False                          # Too many samples to keep in memory at once, so don't preload them\n",
    "ds_opts['aug_type'] = 'basic'                         # Apply all supported augmentations\n",
    "ds_opts['batch_size'] = batch_size * len(gpu_devices) # Use a multiple of 8; here, 16 for dual-GPU mode (Titan X & 1080 Ti)\n",
    "#ds1 = FlyingChairsDataset(mode='train_with_val', ds_root=_FLYINGCHAIRS_ROOT, options=ds_opts)\n",
    "ds_opts['type'] = 'npy'\n",
    "\n",
    "#ds2 = FlyingThings3DHalfResDataset(mode='train_with_val', ds_root=_FLYINGTHINGS3DHALFRES_ROOT, options=ds_opts)\n",
    "#ds = MixedDataset(mode='train_with_val', datasets=[ds1, ds2], options=ds_opts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_opts['crop_preproc'] = (320,960)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ds = MPISintelDataset(mode='train_with_val', ds_root=_MPISINTEL_ROOT, options=ds_opts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = KITTIDataset(mode = 'train_with_val', ds_root=_DATASET_ROOT, options=ds_opts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset Configuration:\n",
      "  verbose              False\n",
      "  in_memory            False\n",
      "  crop_preproc         (320, 960)\n",
      "  scale_preproc        None\n",
      "  type                 npy\n",
      "  tb_test_imgs         False\n",
      "  random_seed          1969\n",
      "  val_split            0.03\n",
      "  aug_type             basic\n",
      "  aug_labels           True\n",
      "  fliplr               0.5\n",
      "  flipud               0.5\n",
      "  translate            (0.5, 0.05)\n",
      "  scale                (0.5, 0.05)\n",
      "  batch_size           2\n",
      "  mode                 train_with_val\n",
      "  train size           2201\n",
      "  val size             69\n"
     ]
    }
   ],
   "source": [
    "# Display dataset configuration\n",
    "ds.print_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure the finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start from the default options\n",
    "nn_opts = deepcopy(_DEFAULT_PWCNET_FINETUNE_OPTIONS)\n",
    "nn_opts['verbose'] = True\n",
    "nn_opts['ckpt_path'] = './pwcnet-lg-6-2-cyclic-sintel_final_finetuned/pwcnet.ckpt-43000'\n",
    "nn_opts['ckpt_dir'] = './pwcnet-lg-6-2-cyclic-KITTI_like_torch/'\n",
    "nn_opts['batch_size'] = 8\n",
    "nn_opts['x_shape'] = [2, ds_opts['crop_preproc'][0], ds_opts['crop_preproc'][1], 3]\n",
    "nn_opts['y_shape'] = [ds_opts['crop_preproc'][0], ds_opts['crop_preproc'][1], 2]\n",
    "nn_opts['use_tf_data'] = False #True # Use tf.data reader\n",
    "nn_opts['gpu_devices'] = gpu_devices\n",
    "nn_opts['controller'] = controller\n",
    "\n",
    "# Use the PWC-Net-small model in quarter-resolution mode\n",
    "nn_opts['use_dense_cx'] = True\n",
    "nn_opts['use_res_cx'] = True\n",
    "nn_opts['pyr_lvls'] = 6\n",
    "nn_opts['flow_pred_lvl'] = 2\n",
    "\n",
    "# Robust loss as described doesn't work, so try the following:\n",
    "nn_opts['loss_fn'] = 'loss_multiscale' # 'loss_multiscale' # 'loss_robust' # 'loss_robust'\n",
    "nn_opts['q'] = 1. # 0.4 # 1. # 0.4 # 1.\n",
    "nn_opts['epsilon'] = 0. # 0.01 # 0. # 0.01 # 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the learning rate schedule. This schedule is for a single GPU using a batch size of 8.\n",
    "# Below,we adjust the schedule to the size of the batch and the number of GPUs.\n",
    "nn_opts['lr_policy'] = 'multisteps'\n",
    "nn_opts['init_lr'] = 1e-05\n",
    "nn_opts['lr_boundaries'] = [80000, 120000, 160000, 200000]\n",
    "nn_opts['lr_values'] = [1e-05, 5e-06, 2.5e-06, 1.25e-06, 6.25e-07]\n",
    "nn_opts['max_steps'] = 200000\n",
    "\n",
    "# Below,we adjust the schedule to the size of the batch and our number of GPUs (2).\n",
    "nn_opts['max_steps'] = int(nn_opts['max_steps'] * 8 / 8)\n",
    "nn_opts['cyclic_lr_stepsize'] = int(nn_opts['cyclic_lr_stepsize'] * 8 / 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building model...\n",
      "... model built.\n",
      "Configuring training ops...\n",
      "... training ops configured.\n",
      "Initializing from pre-trained model at ./pwcnet-lg-6-2-cyclic-sintel_final_finetuned/pwcnet.ckpt-43000 for finetuning...\n",
      "\n",
      "INFO:tensorflow:Restoring parameters from ./pwcnet-lg-6-2-cyclic-sintel_final_finetuned/pwcnet.ckpt-43000\n",
      "... model initialized\n",
      "\n",
      "Model Configuration:\n",
      "  verbose                True\n",
      "  ckpt_path              ./pwcnet-lg-6-2-cyclic-sintel_final_finetuned/pwcnet.ckpt-43000\n",
      "  ckpt_dir               ./pwcnet-lg-6-2-cyclic-KITTI_like_torch/\n",
      "  max_to_keep            10\n",
      "  x_dtype                <dtype: 'float32'>\n",
      "  x_shape                [2, 320, 960, 3]\n",
      "  y_dtype                <dtype: 'float32'>\n",
      "  y_shape                [320, 960, 2]\n",
      "  train_mode             fine-tune\n",
      "  adapt_info             None\n",
      "  sparse_gt_flow         False\n",
      "  display_step           100\n",
      "  snapshot_step          1000\n",
      "  val_step               1000\n",
      "  val_batch_size         -1\n",
      "  tb_val_imgs            top_flow\n",
      "  tb_test_imgs           None\n",
      "  gpu_devices            ['/device:GPU:1']\n",
      "  controller             /device:GPU:1\n",
      "  use_tf_data            False\n",
      "  use_mixed_precision    False\n",
      "  loss_scaler            128.0\n",
      "  batch_size             8\n",
      "  lr_policy              multisteps\n",
      "  max_steps              200000\n",
      "  lr_boundaries          [80000, 120000, 160000, 200000]\n",
      "  lr_values              [1e-05, 5e-06, 2.5e-06, 1.25e-06, 6.25e-07]\n",
      "  loss_fn                loss_multiscale\n",
      "  alphas                 [0.32, 0.08, 0.02, 0.01, 0.005]\n",
      "  gamma                  0.0004\n",
      "  q                      1.0\n",
      "  epsilon                0.0\n",
      "  pyr_lvls               6\n",
      "  flow_pred_lvl          2\n",
      "  search_range           4\n",
      "  use_dense_cx           True\n",
      "  use_res_cx             True\n",
      "  mode                   train_with_val\n",
      "  trainable params       14079050\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the model and display the model configuration\n",
    "nn = ModelPWCNet(mode='train_with_val', options=nn_opts, dataset=ds)\n",
    "nn.print_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finetune the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start finetuning...\n",
      "2019-06-04 13:53:33 Iter 100 [Train]: loss=133.89, epe=3.00, lr=0.000010, samples/sec=4.9, sec/step=1.641, eta=3 days, 19:06:16\n",
      "2019-06-04 13:57:22 Iter 200 [Train]: loss=112.99, epe=2.46, lr=0.000010, samples/sec=5.6, sec/step=1.419, eta=3 days, 6:44:13\n",
      "2019-06-04 14:01:10 Iter 300 [Train]: loss=115.27, epe=2.52, lr=0.000010, samples/sec=5.6, sec/step=1.424, eta=3 days, 6:59:37\n",
      "2019-06-04 14:05:03 Iter 400 [Train]: loss=105.21, epe=2.29, lr=0.000010, samples/sec=5.6, sec/step=1.416, eta=3 days, 6:31:28\n",
      "2019-06-04 14:08:53 Iter 500 [Train]: loss=105.23, epe=2.32, lr=0.000010, samples/sec=5.6, sec/step=1.417, eta=3 days, 6:30:23\n",
      "2019-06-04 14:12:39 Iter 600 [Train]: loss=97.66, epe=2.10, lr=0.000010, samples/sec=5.6, sec/step=1.419, eta=3 days, 6:34:13\n",
      "2019-06-04 14:16:25 Iter 700 [Train]: loss=101.83, epe=2.27, lr=0.000010, samples/sec=5.6, sec/step=1.422, eta=3 days, 6:43:19\n",
      "2019-06-04 14:20:18 Iter 800 [Train]: loss=97.25, epe=2.16, lr=0.000010, samples/sec=5.6, sec/step=1.423, eta=3 days, 6:42:59\n",
      "2019-06-04 14:24:04 Iter 900 [Train]: loss=96.34, epe=2.14, lr=0.000010, samples/sec=5.6, sec/step=1.419, eta=3 days, 6:29:17\n",
      "2019-06-04 14:27:54 Iter 1000 [Train]: loss=94.75, epe=2.10, lr=0.000010, samples/sec=5.6, sec/step=1.420, eta=3 days, 6:28:56\n",
      "2019-06-04 14:28:06 Iter 1000 [Val]: loss=86.43, epe=1.87\n",
      "Saving model...\n",
      "INFO:tensorflow:./pwcnet-lg-6-2-cyclic-KITTI_like_torch/pwcnet.ckpt-1000 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "... model saved in ./pwcnet-lg-6-2-cyclic-KITTI_like_torch/pwcnet.ckpt-1000\n",
      "2019-06-04 14:32:01 Iter 1100 [Train]: loss=97.53, epe=2.17, lr=0.000010, samples/sec=5.6, sec/step=1.424, eta=3 days, 6:38:55\n",
      "2019-06-04 14:35:50 Iter 1200 [Train]: loss=95.46, epe=2.13, lr=0.000010, samples/sec=5.6, sec/step=1.424, eta=3 days, 6:37:53\n",
      "2019-06-04 14:39:42 Iter 1300 [Train]: loss=93.35, epe=2.05, lr=0.000010, samples/sec=5.6, sec/step=1.427, eta=3 days, 6:45:06\n",
      "2019-06-04 14:43:30 Iter 1400 [Train]: loss=89.25, epe=1.96, lr=0.000010, samples/sec=5.6, sec/step=1.428, eta=3 days, 6:45:42\n",
      "2019-06-04 14:47:18 Iter 1500 [Train]: loss=91.37, epe=2.02, lr=0.000010, samples/sec=5.6, sec/step=1.423, eta=3 days, 6:28:40\n",
      "2019-06-04 14:51:02 Iter 1600 [Train]: loss=87.01, epe=1.90, lr=0.000010, samples/sec=5.6, sec/step=1.429, eta=3 days, 6:45:20\n",
      "2019-06-04 14:54:50 Iter 1700 [Train]: loss=94.30, epe=2.11, lr=0.000010, samples/sec=5.6, sec/step=1.424, eta=3 days, 6:27:34\n",
      "2019-06-04 14:58:37 Iter 1800 [Train]: loss=89.93, epe=1.99, lr=0.000010, samples/sec=5.6, sec/step=1.428, eta=3 days, 6:37:56\n",
      "2019-06-04 15:02:27 Iter 1900 [Train]: loss=89.86, epe=1.97, lr=0.000010, samples/sec=5.6, sec/step=1.426, eta=3 days, 6:27:35\n",
      "2019-06-04 15:06:15 Iter 2000 [Train]: loss=85.91, epe=1.87, lr=0.000010, samples/sec=5.6, sec/step=1.428, eta=3 days, 6:31:16\n",
      "2019-06-04 15:06:24 Iter 2000 [Val]: loss=86.93, epe=2.03\n",
      "Saving model...\n",
      "INFO:tensorflow:./pwcnet-lg-6-2-cyclic-KITTI_like_torch/pwcnet.ckpt-2000 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "... model saved in ./pwcnet-lg-6-2-cyclic-KITTI_like_torch/pwcnet.ckpt-2000\n",
      "2019-06-04 15:10:19 Iter 2100 [Train]: loss=85.07, epe=1.85, lr=0.000010, samples/sec=5.6, sec/step=1.425, eta=3 days, 6:20:18\n",
      "2019-06-04 15:14:07 Iter 2200 [Train]: loss=90.00, epe=2.00, lr=0.000010, samples/sec=5.6, sec/step=1.420, eta=3 days, 6:01:47\n",
      "2019-06-04 15:17:58 Iter 2300 [Train]: loss=90.83, epe=2.01, lr=0.000010, samples/sec=5.6, sec/step=1.422, eta=3 days, 6:03:52\n",
      "2019-06-04 15:21:48 Iter 2400 [Train]: loss=84.18, epe=1.82, lr=0.000010, samples/sec=5.6, sec/step=1.417, eta=3 days, 5:48:15\n",
      "2019-06-04 15:25:38 Iter 2500 [Train]: loss=82.81, epe=1.79, lr=0.000010, samples/sec=5.6, sec/step=1.422, eta=3 days, 6:00:13\n",
      "2019-06-04 15:29:23 Iter 2600 [Train]: loss=92.78, epe=2.11, lr=0.000010, samples/sec=5.6, sec/step=1.426, eta=3 days, 6:12:54\n",
      "2019-06-04 15:33:21 Iter 2700 [Train]: loss=83.92, epe=1.81, lr=0.000010, samples/sec=5.6, sec/step=1.419, eta=3 days, 5:47:01\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "nn.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are the training curves for the run above:\n",
    "\n",
    "![](img/pwcnet-sm-6-2-cyclic-chairsthingsmix_finetuned/loss.png)\n",
    "![](img/pwcnet-sm-6-2-cyclic-chairsthingsmix_finetuned/epe.png)\n",
    "![](img/pwcnet-sm-6-2-cyclic-chairsthingsmix_finetuned/lr.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are the predictions issued by the model for a few validation samples:\n",
    "\n",
    "![](img/pwcnet-sm-6-2-cyclic-chairsthingsmix_finetuned/val1.png)\n",
    "![](img/pwcnet-sm-6-2-cyclic-chairsthingsmix_finetuned/val2.png)\n",
    "![](img/pwcnet-sm-6-2-cyclic-chairsthingsmix_finetuned/val3.png)\n",
    "![](img/pwcnet-sm-6-2-cyclic-chairsthingsmix_finetuned/val4.png)\n",
    "![](img/pwcnet-sm-6-2-cyclic-chairsthingsmix_finetuned/val5.png)\n",
    "![](img/pwcnet-sm-6-2-cyclic-chairsthingsmix_finetuned/val6.png)\n",
    "![](img/pwcnet-sm-6-2-cyclic-chairsthingsmix_finetuned/val7.png)\n",
    "![](img/pwcnet-sm-6-2-cyclic-chairsthingsmix_finetuned/val8.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
