{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_directory = None\n",
    "depth_directory = None\n",
    "video_path = None\n",
    "json_path = None\n",
    "csv_path = None\n",
    "txt_path = None\n",
    "\n",
    "weights_dir_path = '../weights'\n",
    "optical_flow_checkpoint = os.path.join('/Vol0/user/f.konokhov/tfoptflow/tfoptflow/tmp',\n",
    "                                       'pwcnet.ckpt-84000')\n",
    "\n",
    "depth_estimator_name = 'struct2depth'\n",
    "depth_checkpoint = os.path.join(weights_dir_path, 'model-199160')\n",
    "#depth_estimator_name = 'senet'\n",
    "\n",
    "computation_kwargs = dict(\n",
    "    cuda_visible_devices=0,\n",
    ")\n",
    "\n",
    "sys.path.append(os.path.abspath(os.pardir))\n",
    "sys.path.append(os.path.join(os.path.abspath(os.pardir), 'submodules/tf_models/research/struct2depth'))\n",
    "sys.path.append(os.path.join(os.path.abspath(os.pardir), 'submodules/tfoptflow/tfoptflow'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from prepare_dataset.dataset_builder import ImagesDatasetBuilder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using FPS rate = 30\n"
     ]
    }
   ],
   "source": [
    "sequence_directory = '03'\n",
    "\n",
    "builder = ImagesDatasetBuilder(\n",
    "     sequence_directory=sequence_directory,\n",
    "     build_from='DISCOMAN',\n",
    "     image_directory='/dbstore/datasets/KITTI_odometry_2012/dataset/sequences/03/image_2',\n",
    "     mode=ImagesDatasetBuilder.TEST,\n",
    "     estimate_optical_flow=True,\n",
    "     optical_flow_estimator_name='pwc',\n",
    "     optical_flow_checkpoint=optical_flow_checkpoint,\n",
    "     estimate_depth=False,\n",
    "     depth_estimator_name=depth_estimator_name,\n",
    "     depth_checkpoint=depth_checkpoint,\n",
    "     memory_safe=True,\n",
    "     **computation_kwargs)\n",
    "builder._configure()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using FPS rate = 30\n",
      "Estimate optical flow\n",
      "Model:   <class 'prepare_dataset.estimator.PWCOpticalFlowEstimator'>\n",
      "Weights: /Vol0/user/f.konokhov/tfoptflow/tfoptflow/tmp/pwcnet.ckpt-84000\n",
      "Output:  03/optical_flow_stride1\n",
      "\n",
      "==================================================================================================\n",
      "\n",
      "Computation settings:\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA visible devices:     0\n",
      "Available GPUs:           /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Allow growth:             True\n",
      "GPU memory fraction:      0.33\n",
      "Number of CPU:            8\n",
      "Number of CPU threads:    16\n",
      "\n",
      "Random seed:              42\n",
      "\n",
      "==================================================================================================\n",
      "\n",
      "\n",
      "Building model...\n",
      "WARNING:tensorflow:From /Vol0/user/a.vorontsova/odometry/submodules/tfoptflow/tfoptflow/model_pwcnet.py:1173: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.conv2d instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0604 16:19:07.163080 47974054530688 deprecation.py:323] From /Vol0/user/a.vorontsova/odometry/submodules/tfoptflow/tfoptflow/model_pwcnet.py:1173: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.conv2d instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Vol0/user/a.vorontsova/miniconda3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0604 16:19:07.285285 47974054530688 deprecation.py:323] From /Vol0/user/a.vorontsova/miniconda3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Vol0/user/a.vorontsova/odometry/submodules/tfoptflow/tfoptflow/model_pwcnet.py:1300: conv2d_transpose (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.conv2d_transpose instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0604 16:19:08.920270 47974054530688 deprecation.py:323] From /Vol0/user/a.vorontsova/odometry/submodules/tfoptflow/tfoptflow/model_pwcnet.py:1300: conv2d_transpose (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.conv2d_transpose instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... model built.\n",
      "Loading model checkpoint /Vol0/user/f.konokhov/tfoptflow/tfoptflow/tmp/pwcnet.ckpt-84000 for eval or testing...\n",
      "\n",
      "WARNING:tensorflow:From /Vol0/user/a.vorontsova/miniconda3/lib/python3.6/site-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0604 16:19:13.639808 47974054530688 deprecation.py:323] From /Vol0/user/a.vorontsova/miniconda3/lib/python3.6/site-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /Vol0/user/f.konokhov/tfoptflow/tfoptflow/tmp/pwcnet.ckpt-84000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0604 16:19:13.743767 47974054530688 saver.py:1270] Restoring parameters from /Vol0/user/f.konokhov/tfoptflow/tfoptflow/tmp/pwcnet.ckpt-84000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... model loaded\n",
      "Estimator(dir=03/optical_flow_stride1, image_manager=ImageManager(dir=/dbstore/datasets/KITTI_odometry_2012/dataset/sequences/03/image_2, image_height=375, image_width=1242, stride=1, sample=True, step=1), checkpoint=/Vol0/user/f.konokhov/tfoptflow/tfoptflow/tmp/pwcnet.ckpt-84000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Optical flow estimation: 100%|██████████| 800/800 [02:23<00:00,  4.01it/s]\n"
     ]
    }
   ],
   "source": [
    "builder.build() # \"Do everything\" big red button"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "builder.dataframe.to_csv(sequence_directory + '/df.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Visual Odometry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_size = (96, 320)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  5.25it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 82.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from prepare_dataset.generator_factory import GeneratorFactory\n",
    "dataset = GeneratorFactory(\n",
    "    csv_name=('df.csv'),\n",
    "    dataset_root='/Vol0/user/a.vorontsova/odometry/notebooks',\n",
    "    train_sequences=[sequence_directory],\n",
    "    val_sequences=[sequence_directory],\n",
    "    target_size=target_size,\n",
    "    x_col=['path_to_optical_flow'],\n",
    "    y_col=['euler_x', 'euler_y', 'euler_z', 'x', 'y', 'z'],\n",
    "    image_columns=['path_to_optical_flow'],\n",
    "    load_modes=['flow_xy'],\n",
    "    preprocess_modes=['flow_xy'],\n",
    "    val_sampling_step=1,\n",
    "    cached_imgs=None,\n",
    "    batch_size=32\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.df_val.path_to_optical_flow = dataset.df_val.path_to_optical_flow.str.replace(\n",
    "    '/{}/'.format(sequence_directory), '/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Vol0/user/a.vorontsova/miniconda3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0604 16:24:14.079601 47974054530688 deprecation.py:323] From /Vol0/user/a.vorontsova/miniconda3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load weights from /Vol0/user/f.konokhov/FlavorNet/models/kitty_train0289/weights/models-kitty_train0289-ls_vo_pwc_classic.100-0.101066.hdf5\n",
      "WARNING:tensorflow:From /Vol0/user/a.vorontsova/miniconda3/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0604 16:24:40.796696 47974054530688 deprecation.py:323] From /Vol0/user/a.vorontsova/miniconda3/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    }
   ],
   "source": [
    "from models.model_factory import ModelFactory\n",
    "\n",
    "model_factory = ModelFactory(\n",
    "    target_size,\n",
    "    channels_counts=dataset.channels_counts,\n",
    "    lr=0.001,\n",
    "    loss='mae',\n",
    "    scale_rotation=50\n",
    ")\n",
    "model = model_factory.construct_pretrained_model(\n",
    "    '/Vol0/user/f.konokhov/FlavorNet/models/kitty_train0289/weights/models-kitty_train0289-ls_vo_pwc_classic.100-0.101066.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No cache\n"
     ]
    }
   ],
   "source": [
    "generator = dataset.get_val_generator()\n",
    "model_output = model.predict_generator(generator, steps=len(generator))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from linalg.trajectory import RelativeTrajectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = ['euler_x', 'euler_y', 'euler_z', 'x', 'y', 'z']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt = builder.dataframe[keys].to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_relative_trajectory = RelativeTrajectory()\n",
    "gt_relative_trajectory.from_euler_angles(gt)\n",
    "gt_global_trajectory = gt_relative_trajectory.relative_to_global()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = [dict(zip(keys, values)) for values in np.concatenate(model_output, 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_relative_trajectory = RelativeTrajectory()\n",
    "predicted_relative_trajectory.from_euler_angles(predictions)\n",
    "predicted_global_trajectory = predicted_relative_trajectory.relative_to_global()\n",
    "predicted_global_trajectory.plot('tmp.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluation.visualization_utils import visualize_trajectory\n",
    "visualize_trajectory(predicted_global_trajectory, title=sequence_directory, is_3d=True, file_name='tmp_3d.html')\n",
    "visualize_trajectory(predicted_global_trajectory, title=sequence_directory, is_3d=False, file_name='tmp_2d.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluation.visualization_utils import visualize_trajectory\n",
    "visualize_trajectory(gt_global_trajectory, title=sequence_directory, is_3d=True, file_name='gt_3d.html')\n",
    "visualize_trajectory(gt_global_trajectory, title=sequence_directory, is_3d=False, file_name='gt_2d.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluation.visualization_utils import visualize_trajectory_with_gt\n",
    "visualize_trajectory_with_gt(gt_global_trajectory, predicted_global_trajectory, title=sequence_directory, is_3d=True, file_name='tmp_gt_3d.html')\n",
    "visualize_trajectory_with_gt(gt_global_trajectory, predicted_global_trajectory, title=sequence_directory, is_3d=False, file_name='tmp_gt_2d.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "444.5658312587294"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from evaluation.metrics import ATE\n",
    "ATE(gt_global_trajectory, predicted_global_trajectory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
