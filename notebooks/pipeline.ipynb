{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Jun 20 16:16:38 2019       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 418.40.04    Driver Version: 418.40.04    CUDA Version: 10.1     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla P40           Off  | 00000000:04:00.0 Off |                  Off |\n",
      "| N/A   29C    P8     9W / 250W |      0MiB / 24451MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  Tesla P40           Off  | 00000000:06:00.0 Off |                  Off |\n",
      "| N/A   47C    P0   104W / 250W |   4279MiB / 24451MiB |     74%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  Tesla P40           Off  | 00000000:0D:00.0 Off |                  Off |\n",
      "| N/A   32C    P8    10W / 250W |      0MiB / 24451MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  Tesla P40           Off  | 00000000:0E:00.0 Off |                  Off |\n",
      "| N/A   32C    P8    10W / 250W |      0MiB / 24451MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "|    1     30598      C   python                                      4269MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "CUDA_VISIBLE_DEVICES = '0,2,3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "\n",
    "import __init_path__\n",
    "import env\n",
    "import mlflow\n",
    "from odometry.utils import make_memory_safe\n",
    "from odometry.preprocessing import parsers, estimators, prepare_trajectory\n",
    "from odometry.data_manager import GeneratorFactory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_parser():\n",
    "    trajectory_dir = 'discoman'\n",
    "    json_path = os.path.join(env.DATASET_PATH, 'renderbox/iros2019/dset/output/deprecated/000001/0_traj.json')\n",
    "    parser = parsers.DISCOMANParser(trajectory_dir, json_path)\n",
    "    return parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_estimators(target_size):\n",
    "    quaternion2euler_estimator = estimators.Quaternion2EulerEstimator(input_col=['q_w', 'q_x', 'q_y', 'q_z'],\n",
    "                                                                      output_col=['euler_x', 'euler_y', 'euler_z'])\n",
    "    \n",
    "    depth_checkpoint = os.path.abspath('../weights/model-199160')\n",
    "    struct2depth_estimator = estimators.Struct2DepthEstimator(input_col='path_to_rgb',\n",
    "                                                              output_col='path_to_depth',\n",
    "                                                              sub_dir='depth',\n",
    "                                                              checkpoint=depth_checkpoint, \n",
    "                                                              height=target_size[0],\n",
    "                                                              width=target_size[1])\n",
    "    \n",
    "    cols = ['euler_x', 'euler_y', 'euler_z', 't_x', 't_y', 't_z']\n",
    "    input_col = cols + [col + '_next' for col in cols]\n",
    "    output_col = cols\n",
    "    global2relative_estimator = estimators.Global2RelativeEstimator(input_col=input_col,\n",
    "                                                                    output_col=output_col)\n",
    "    \n",
    "    optical_flow_checkpoint = '/Vol0/user/f.konokhov/tfoptflow/tfoptflow/tmp/pwcnet.ckpt-84000'\n",
    "    #optical_flow_checkpoint = os.path.abspath(../weights/pwcnet.ckpt-595000')  # official weights\n",
    "    pwcnet_estimator = estimators.PWCNetEstimator(input_col=['path_to_rgb', 'path_to_rgb_next'],\n",
    "                                                  output_col='path_to_optical_flow',\n",
    "                                                  sub_dir='optical_flow',\n",
    "                                                  checkpoint=optical_flow_checkpoint)\n",
    "    \n",
    "    single_frame_estimators = [quaternion2euler_estimator, struct2depth_estimator]\n",
    "    pair_frames_estimators = [global2relative_estimator, pwcnet_estimator]\n",
    "    return single_frame_estimators, pair_frames_estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def prepare_dataset(trajectory_names, target_size):\n",
    "    parser = initialize_parser()\n",
    "    single_frame_estimators, pair_frames_estimators = initialize_estimators(target_size)\n",
    "    for trajectory_name in trajectory_names:\n",
    "        trajectory_dir = 'discoman/{}'.format(trajectory_name)\n",
    "        df = prepare_trajectory(trajectory_dir, \n",
    "                                parser=parser, \n",
    "                                single_frame_estimators=single_frame_estimators,\n",
    "                                pair_frames_estimators=pair_frames_estimators,\n",
    "                                stride=1)\n",
    "        df.to_csv(os.path.join(trajectory_dir, 'df.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# toy example\n",
    "config = { \n",
    "    \"train_sequences\": [\n",
    "        \"train/0085\",\n",
    "    ],\n",
    "    \"val_sequences\": [\n",
    "        \"val/0007\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "target_size = (120, 160)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -r discoman"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================================================================\n",
      "\n",
      "Computation settings:\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA visible devices:     0,2,3\n",
      "Available GPUs:           /job:localhost/replica:0/task:0/device:GPU:0, /job:localhost/replica:0/task:0/device:GPU:1, /job:localhost/replica:0/task:0/device:GPU:2\n",
      "Allow growth:             True\n",
      "GPU memory fraction:      0.33\n",
      "Number of CPU:            8\n",
      "Number of CPU threads:    16\n",
      "\n",
      "Random seed:              42\n",
      "\n",
      "==================================================================================================\n",
      "\n",
      "\n",
      "WARNING:tensorflow:From /Vol0/user/a.vorontsova/miniconda3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0620 16:19:02.653527 47083014344320 deprecation.py:323] From /Vol0/user/a.vorontsova/miniconda3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Vol0/user/a.vorontsova/odometry/submodules/tf_models/research/struct2depth/nets.py:503: batch_normalization (from tensorflow.python.layers.normalization) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.batch_normalization instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0620 16:19:02.777057 47083014344320 deprecation.py:323] From /Vol0/user/a.vorontsova/odometry/submodules/tf_models/research/struct2depth/nets.py:503: batch_normalization (from tensorflow.python.layers.normalization) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.batch_normalization instead.\n",
      "W0620 16:19:05.206167 47083014344320 util.py:204] Shape mismatch, will not restore egomotion_prediction/pose_exp_net/pose/cnv6/weights.\n",
      "W0620 16:19:05.207139 47083014344320 util.py:206] The following variables in the checkpoint were not loaded:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Vol0/user/a.vorontsova/miniconda3/lib/python3.6/site-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0620 16:19:05.334118 47083014344320 deprecation.py:323] From /Vol0/user/a.vorontsova/miniconda3/lib/python3.6/site-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /Vol0/user/a.vorontsova/odometry/weights/model-199160\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0620 16:19:05.336912 47083014344320 saver.py:1270] Restoring parameters from /Vol0/user/a.vorontsova/odometry/weights/model-199160\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building model...\n",
      "WARNING:tensorflow:From /Vol0/user/a.vorontsova/odometry/submodules/tfoptflow/tfoptflow/model_pwcnet.py:1173: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.conv2d instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0620 16:19:15.842883 47083014344320 deprecation.py:323] From /Vol0/user/a.vorontsova/odometry/submodules/tfoptflow/tfoptflow/model_pwcnet.py:1173: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.conv2d instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Vol0/user/a.vorontsova/odometry/submodules/tfoptflow/tfoptflow/model_pwcnet.py:1300: conv2d_transpose (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.conv2d_transpose instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0620 16:19:17.142702 47083014344320 deprecation.py:323] From /Vol0/user/a.vorontsova/odometry/submodules/tfoptflow/tfoptflow/model_pwcnet.py:1300: conv2d_transpose (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.conv2d_transpose instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... model built.\n",
      "Loading model checkpoint /Vol0/user/f.konokhov/tfoptflow/tfoptflow/tmp/pwcnet.ckpt-84000 for eval or testing...\n",
      "\n",
      "INFO:tensorflow:Restoring parameters from /Vol0/user/f.konokhov/tfoptflow/tfoptflow/tmp/pwcnet.ckpt-84000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0620 16:19:21.677202 47083014344320 saver.py:1270] Restoring parameters from /Vol0/user/f.konokhov/tfoptflow/tfoptflow/tmp/pwcnet.ckpt-84000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... model loaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Quaternion2Euler    : 100%|██████████| 2131/2131 [00:07<00:00, 296.46it/s]\n",
      "Struct2Depth        : 100%|██████████| 2131/2131 [00:55<00:00, 38.72it/s]\n",
      "Global2Relative     : 100%|██████████| 2130/2130 [00:13<00:00, 155.49it/s]\n",
      "PWCNet              : 100%|██████████| 2130/2130 [02:17<00:00, 15.50it/s]\n",
      "Quaternion2Euler    : 100%|██████████| 2131/2131 [00:06<00:00, 310.63it/s]\n",
      "Struct2Depth        : 100%|██████████| 2131/2131 [00:44<00:00, 48.05it/s]\n",
      "Global2Relative     : 100%|██████████| 2130/2130 [00:13<00:00, 158.47it/s]\n",
      "PWCNet              : 100%|██████████| 2130/2130 [02:11<00:00, 16.21it/s]\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "\n",
    "make_memory_safe(prepare_dataset, cuda_visible_devices=CUDA_VISIBLE_DEVICES)(\n",
    "    itertools.chain(config['train_sequences'], config['val_sequences']),\n",
    "    target_size=target_size\n",
    ")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train  val\r\n"
     ]
    }
   ],
   "source": [
    "!ls discoman"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Odometry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 13.03it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 34.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set empty cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "dataset = GeneratorFactory(\n",
    "    csv_name='df.csv',\n",
    "    dataset_root='discoman',\n",
    "    train_sequences=config['train_sequences'],\n",
    "    val_sequences=config['val_sequences'],\n",
    "    target_size=target_size,\n",
    "    x_col=['path_to_optical_flow'],\n",
    "    y_col=['euler_x', 'euler_y', 'euler_z', 't_x', 't_y', 't_z'],\n",
    "    image_columns=['path_to_optical_flow'],\n",
    "    load_modes=['flow_xy'],\n",
    "    preprocess_modes=['flow_xy'],\n",
    "    val_sampling_step=2,\n",
    "    cached_imgs={}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(120, 160, 2)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.input_shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path_to_depth</th>\n",
       "      <th>path_to_rgb</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>path_to_depth_next</th>\n",
       "      <th>path_to_rgb_next</th>\n",
       "      <th>timestamp_next</th>\n",
       "      <th>euler_x</th>\n",
       "      <th>euler_y</th>\n",
       "      <th>euler_z</th>\n",
       "      <th>t_x</th>\n",
       "      <th>t_y</th>\n",
       "      <th>t_z</th>\n",
       "      <th>path_to_optical_flow</th>\n",
       "      <th>trajectory_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>depth/0.npy</td>\n",
       "      <td>rgb/0.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>depth/1.npy</td>\n",
       "      <td>rgb/1.jpg</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>-0.000698</td>\n",
       "      <td>4.821875e-07</td>\n",
       "      <td>-0.000002</td>\n",
       "      <td>-0.000005</td>\n",
       "      <td>0.000244</td>\n",
       "      <td>val/0007/optical_flow/0_1.npy</td>\n",
       "      <td>val/0007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>depth/2.npy</td>\n",
       "      <td>rgb/2.jpg</td>\n",
       "      <td>10</td>\n",
       "      <td>depth/3.npy</td>\n",
       "      <td>rgb/3.jpg</td>\n",
       "      <td>15</td>\n",
       "      <td>0.000166</td>\n",
       "      <td>-0.004189</td>\n",
       "      <td>5.193066e-05</td>\n",
       "      <td>-0.000038</td>\n",
       "      <td>-0.000020</td>\n",
       "      <td>0.001501</td>\n",
       "      <td>val/0007/optical_flow/2_3.npy</td>\n",
       "      <td>val/0007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>depth/4.npy</td>\n",
       "      <td>rgb/4.jpg</td>\n",
       "      <td>20</td>\n",
       "      <td>depth/5.npy</td>\n",
       "      <td>rgb/5.jpg</td>\n",
       "      <td>25</td>\n",
       "      <td>0.000546</td>\n",
       "      <td>-0.007674</td>\n",
       "      <td>-3.795352e-04</td>\n",
       "      <td>0.000367</td>\n",
       "      <td>-0.000097</td>\n",
       "      <td>0.002686</td>\n",
       "      <td>val/0007/optical_flow/4_5.npy</td>\n",
       "      <td>val/0007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>depth/6.npy</td>\n",
       "      <td>rgb/6.jpg</td>\n",
       "      <td>30</td>\n",
       "      <td>depth/7.npy</td>\n",
       "      <td>rgb/7.jpg</td>\n",
       "      <td>35</td>\n",
       "      <td>0.000459</td>\n",
       "      <td>-0.011167</td>\n",
       "      <td>-1.948336e-04</td>\n",
       "      <td>0.000145</td>\n",
       "      <td>-0.000071</td>\n",
       "      <td>0.003850</td>\n",
       "      <td>val/0007/optical_flow/6_7.npy</td>\n",
       "      <td>val/0007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>depth/8.npy</td>\n",
       "      <td>rgb/8.jpg</td>\n",
       "      <td>40</td>\n",
       "      <td>depth/9.npy</td>\n",
       "      <td>rgb/9.jpg</td>\n",
       "      <td>45</td>\n",
       "      <td>0.000588</td>\n",
       "      <td>-0.014653</td>\n",
       "      <td>-6.542083e-04</td>\n",
       "      <td>0.000454</td>\n",
       "      <td>-0.000208</td>\n",
       "      <td>0.004835</td>\n",
       "      <td>val/0007/optical_flow/8_9.npy</td>\n",
       "      <td>val/0007</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  path_to_depth path_to_rgb  timestamp path_to_depth_next path_to_rgb_next  \\\n",
       "0   depth/0.npy   rgb/0.jpg          0        depth/1.npy        rgb/1.jpg   \n",
       "2   depth/2.npy   rgb/2.jpg         10        depth/3.npy        rgb/3.jpg   \n",
       "4   depth/4.npy   rgb/4.jpg         20        depth/5.npy        rgb/5.jpg   \n",
       "6   depth/6.npy   rgb/6.jpg         30        depth/7.npy        rgb/7.jpg   \n",
       "8   depth/8.npy   rgb/8.jpg         40        depth/9.npy        rgb/9.jpg   \n",
       "\n",
       "   timestamp_next   euler_x   euler_y       euler_z       t_x       t_y  \\\n",
       "0               5  0.000028 -0.000698  4.821875e-07 -0.000002 -0.000005   \n",
       "2              15  0.000166 -0.004189  5.193066e-05 -0.000038 -0.000020   \n",
       "4              25  0.000546 -0.007674 -3.795352e-04  0.000367 -0.000097   \n",
       "6              35  0.000459 -0.011167 -1.948336e-04  0.000145 -0.000071   \n",
       "8              45  0.000588 -0.014653 -6.542083e-04  0.000454 -0.000208   \n",
       "\n",
       "        t_z           path_to_optical_flow trajectory_id  \n",
       "0  0.000244  val/0007/optical_flow/0_1.npy      val/0007  \n",
       "2  0.001501  val/0007/optical_flow/2_3.npy      val/0007  \n",
       "4  0.002686  val/0007/optical_flow/4_5.npy      val/0007  \n",
       "6  0.003850  val/0007/optical_flow/6_7.npy      val/0007  \n",
       "8  0.004835  val/0007/optical_flow/8_9.npy      val/0007  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.df_val.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Vol0/user/a.vorontsova/miniconda3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0620 16:33:07.225721 47083014344320 deprecation.py:323] From /Vol0/user/a.vorontsova/miniconda3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN\n",
      "Set empty cache\n",
      "WARNING:tensorflow:From /Vol0/user/a.vorontsova/miniconda3/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0620 16:33:07.795037 47083014344320 deprecation.py:323] From /Vol0/user/a.vorontsova/miniconda3/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "17/17 [==============================] - 36s 2s/step - loss: 1.1876 - euler_x_loss: 0.0044 - euler_y_loss: 0.0136 - euler_z_loss: 0.0053 - t_x_loss: 0.0039 - t_y_loss: 0.0059 - t_z_loss: 0.0112 - euler_x_rmse: 0.0044 - euler_y_rmse: 0.0136 - euler_z_rmse: 0.0053 - t_x_rmse: 0.0040 - t_y_rmse: 0.0059 - t_z_rmse: 0.0112\n",
      "PREDICT\n",
      "EVALUATE\n",
      "{'ATE': 8.057516130349205, 'RMSE_t': 10.31881839916596, 'RMSE_r': 2.3203031168905704e-06, 'RPE_t': 4362245.302380594, 'RPE_r': 0.7713171937197248, 'RPE_divider': 567645}\n"
     ]
    }
   ],
   "source": [
    "def train(dataset):\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    from functools import partial\n",
    "    \n",
    "    from odometry.models import ModelFactory, construct_flexible_model\n",
    "    from odometry.linalg import RelativeTrajectory\n",
    "    from odometry.evaluation import calculate_metrics\n",
    "    from odometry.utils import visualize_trajectory, visualize_trajectory_with_gt\n",
    "    \n",
    "    \n",
    "    construct_graph_fn = partial(construct_flexible_model, use_gated_convolutions=False)\n",
    "    model_factory = ModelFactory(\n",
    "        construct_graph_fn,\n",
    "        input_shapes=dataset.input_shapes,\n",
    "        lr=0.001,\n",
    "        loss='mae',\n",
    "        scale_rotation=50\n",
    "    )\n",
    "    model = model_factory.construct()\n",
    "\n",
    "    print('TRAIN')\n",
    "    train_generator = dataset.get_train_generator()\n",
    "    model.fit_generator(train_generator, steps_per_epoch=len(train_generator), epochs=1)\n",
    "    \n",
    "    print('PREDICT')\n",
    "    val_generator = dataset.get_val_generator()\n",
    "    model_output = model.predict_generator(val_generator, steps=len(val_generator))\n",
    "    predictions = pd.DataFrame(data=np.concatenate(model_output, 1), \n",
    "                               index=dataset.df_val.index,\n",
    "                               columns=dataset.y_col)\n",
    "    \n",
    "    print('EVALUATE')\n",
    "    for trajectory_id, indices in dataset.df_val.groupby(by='trajectory_id').indices.items():\n",
    "        trajectory_id = trajectory_id.replace('/', '_')\n",
    "\n",
    "        gt_trajectory = RelativeTrajectory.from_dataframe(dataset.df_val.iloc[indices]).to_global()\n",
    "        predicted_trajectory = RelativeTrajectory.from_dataframe(predictions.iloc[indices]).to_global()\n",
    "\n",
    "        predicted_trajectory.plot('plot_{}.html'.format(trajectory_id))\n",
    "\n",
    "        metrics = calculate_metrics(gt_trajectory, predicted_trajectory)\n",
    "        print(metrics)\n",
    "        \n",
    "        title = '{}: {}'.format(trajectory_id.upper(), metrics)\n",
    "        visualize_trajectory(predicted_trajectory, title=title, is_3d=True,\n",
    "                             file_name='visualize_3d_{}.html'.format(trajectory_id))\n",
    "        visualize_trajectory(predicted_trajectory, title=title, is_3d=False,\n",
    "                             file_name='visualize_2d_{}.html'.format(trajectory_id))\n",
    "\n",
    "        visualize_trajectory_with_gt(gt_trajectory, predicted_trajectory, title=title, is_3d=True,\n",
    "                                     file_name='visualize_3d_with_gt_{}.html'.format(trajectory_id))\n",
    "        visualize_trajectory_with_gt(gt_trajectory, predicted_trajectory, title=title, is_3d=False,\n",
    "                                     file_name='visualize_2d_with_gt_{}.html'.format(trajectory_id))\n",
    "    \n",
    "mlflow.set_experiment(\"pipeline\")\n",
    "with mlflow.start_run(run_name=\"basic_setup\"):\n",
    "    mlflow.log_param(\"val_sequences\", config[\"val_sequences\"])\n",
    "    train(dataset)\n",
    "#make_memory_safe(train, cuda_visible_devices=CUDA_VISIBLE_DEVICES)(dataset) # mysteriously fails with pyquaternion sometimes   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}