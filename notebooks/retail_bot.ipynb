{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_directory = None\n",
    "depth_directory = None\n",
    "video_path = None\n",
    "json_path = None\n",
    "csv_path = None\n",
    "txt_path = None\n",
    "\n",
    "weights_dir_path = '../weights'\n",
    "optical_flow_checkpoint = os.path.join('/Vol0/user/f.konokhov/tfoptflow/tfoptflow/pwcnet-lg-6-2-cyclic-KITTI_finetuned',\n",
    "                                       'pwcnet.ckpt-84000')\n",
    "\n",
    "depth_estimator_name = 'struct2depth'\n",
    "depth_checkpoint = os.path.join(weights_dir_path, 'model-199160')\n",
    "#depth_estimator_name = 'senet'\n",
    "\n",
    "computation_kwargs = dict(\n",
    "    cuda_visible_devices=0,\n",
    ")\n",
    "\n",
    "sys.path.append(os.path.join(os.path.abspath(os.pardir), 'submodules/tf_models/research/struct2depth'))\n",
    "sys.path.append(os.path.join(os.path.abspath(os.pardir), 'submodules/tfoptflow/tfoptflow'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from prepare_dataset.dataset_builder import ImagesDatasetBuilder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using FPS rate = 30\n"
     ]
    }
   ],
   "source": [
    "sequence_directory = 'meetingroom_04_rgbd_ir_imu_pose_KITTI_finetuned'\n",
    "\n",
    "builder = ImagesDatasetBuilder(\n",
    "     sequence_directory=sequence_directory,\n",
    "     build_from='DIRECTORY',\n",
    "     image_directory='/dbstore/datasets/retail_bot/meetingroom_04_rgbd_ir_imu_pose/data_rgb',\n",
    "#    txt_path=txt_path,\n",
    "     mode=ImagesDatasetBuilder.TEST,\n",
    "     estimate_optical_flow=True,\n",
    "     optical_flow_estimator_name='pwc',\n",
    "     optical_flow_checkpoint=optical_flow_checkpoint,\n",
    "     estimate_depth=False,\n",
    "     depth_estimator_name=depth_estimator_name,\n",
    "     depth_checkpoint=depth_checkpoint,\n",
    "     memory_safe=True,\n",
    "     **computation_kwargs)\n",
    "builder._configure()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using FPS rate = 30\n",
      "Estimate optical flow\n",
      "Model:   <class 'prepare_dataset.estimator.PWCOpticalFlowEstimator'>\n",
      "Weights: /Vol0/user/f.konokhov/tfoptflow/tfoptflow/pwcnet-lg-6-2-cyclic-KITTI_finetuned/pwcnet.ckpt-84000\n",
      "Output:  meetingroom_04_rgbd_ir_imu_pose_KITTI_finetuned/optical_flow_stride1\n",
      "\n",
      "==================================================================================================\n",
      "\n",
      "Computation settings:\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA visible devices:     0\n",
      "Available GPUs:           /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Allow growth:             True\n",
      "GPU memory fraction:      0.33\n",
      "Number of CPU:            8\n",
      "Number of CPU threads:    16\n",
      "\n",
      "Random seed:              42\n",
      "\n",
      "==================================================================================================\n",
      "\n",
      "\n",
      "Building model...\n",
      "... model built.\n",
      "Loading model checkpoint /Vol0/user/f.konokhov/tfoptflow/tfoptflow/pwcnet-lg-6-2-cyclic-KITTI_finetuned/pwcnet.ckpt-84000 for eval or testing...\n",
      "\n",
      "INFO:tensorflow:Restoring parameters from /Vol0/user/f.konokhov/tfoptflow/tfoptflow/pwcnet-lg-6-2-cyclic-KITTI_finetuned/pwcnet.ckpt-84000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "I0603 15:49:30.195708 47366295576192 tf_logging.py:115] Restoring parameters from /Vol0/user/f.konokhov/tfoptflow/tfoptflow/pwcnet-lg-6-2-cyclic-KITTI_finetuned/pwcnet.ckpt-84000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... model loaded\n",
      "Estimator(dir=meetingroom_04_rgbd_ir_imu_pose_KITTI_finetuned/optical_flow_stride1, image_manager=ImageManager(dir=/dbstore/datasets/retail_bot/meetingroom_04_rgbd_ir_imu_pose/data_rgb, image_height=480, image_width=640, stride=1, sample=True, step=1), checkpoint=/Vol0/user/f.konokhov/tfoptflow/tfoptflow/pwcnet-lg-6-2-cyclic-KITTI_finetuned/pwcnet.ckpt-84000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Optical flow estimation: 100%|██████████| 5262/5262 [16:09<00:00,  4.92it/s]\n"
     ]
    }
   ],
   "source": [
    "builder.build() # \"Do everything\" big red button"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "builder.dataframe.to_csv(sequence_directory + '/df.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Visual Odometry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_size = (120, 160)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  6.08it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 35.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No cache\n"
     ]
    }
   ],
   "source": [
    "from prepare_dataset.generator_factory import GeneratorFactory\n",
    "dataset = GeneratorFactory(\n",
    "    csv_name=('df.csv'),\n",
    "    dataset_root='/Vol0/user/i.slynko/projects/odometry/notebooks',\n",
    "    train_sequences=[sequence_directory],\n",
    "    val_sequences=[sequence_directory],\n",
    "    target_size=target_size,\n",
    "    x_col=['path_to_optical_flow'],\n",
    "    y_col=['euler_x', 'euler_y', 'euler_z', 'x', 'y', 'z'],\n",
    "    image_columns=['path_to_optical_flow'],\n",
    "    load_modes=['flow_xy'],\n",
    "    preprocess_modes=['flow_xy'],\n",
    "    val_sampling_step=1,\n",
    "    cached_imgs=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.df_val.path_to_optical_flow = dataset.df_val.path_to_optical_flow.str.replace(\n",
    "    '/{}/'.format(sequence_directory), '/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load weights from /Vol0/user/f.konokhov/FlavorNet/models/suncg_v04/weights/models-suncg_v04-ls_vo_no_decoder_kitti_flow.110-0.000146.hdf5\n"
     ]
    }
   ],
   "source": [
    "from models.model_factory import ModelFactory\n",
    "\n",
    "model_factory = ModelFactory(\n",
    "    target_size,\n",
    "    channels_counts=dataset.channels_counts,\n",
    "    lr=0.001,\n",
    "    loss='mae',\n",
    "    scale_rotation=50\n",
    ")\n",
    "model = model_factory.construct_pretrained_model(\n",
    "    '/Vol0/user/f.konokhov/FlavorNet/models/suncg_v04/weights/models-suncg_v04-ls_vo_no_decoder_kitti_flow.110-0.000146.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No cache\n"
     ]
    }
   ],
   "source": [
    "generator = dataset.get_val_generator()\n",
    "model_output = model.predict_generator(generator, steps=len(generator))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: recheck naming\n",
    "# list of dicts is overcomplecated!\n",
    "\n",
    "predictions = {'yaw':   model_output[0].flatten(), \n",
    "               'pitch': model_output[1].flatten(), \n",
    "               'roll':  model_output[2].flatten(), \n",
    "               'tx':    model_output[3].flatten(), \n",
    "               'ty':    model_output[4].flatten(),\n",
    "               'tz':    model_output[5].flatten()}\n",
    "\n",
    "predictions_transposed = [dict(zip(predictions, col)) for col in zip(*predictions.values())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('/Vol0/user/i.slynko/projects/FlavorNet/utilities/convertors')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trajectory import RelativeTrajectory\n",
    "trajectory = RelativeTrajectory()\n",
    "trajectory.from_euler_angles(predictions_transposed) # from_euler_angles should return self (see DataFrame)\n",
    "trajectory.relative_to_global().plot('tmp.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tmp\n",
      "No cache\n",
      "trajectory meetingroom_04_rgbd_ir_imu_pose_KITTI_finetuned\n",
      "saved 6-dof to predictions/tmp/6dof/meetingroom_04_rgbd_ir_imu_pose_KITTI_finetuned.csv\n",
      "saved global se3 to predictions/tmp/se3/meetingroom_04_rgbd_ir_imu_pose_KITTI_finetuned.txt\n",
      "saved global poses to predictions/tmp/poses/meetingroom_04_rgbd_ir_imu_pose_KITTI_finetuned.txt\n"
     ]
    }
   ],
   "source": [
    "# Old visualization:\n",
    "sys.path.append('/Vol0/user/i.slynko/projects')\n",
    "sys.path.append('/Vol0/user/i.slynko/projects/FlavorNet/utilities/slam_metrics')\n",
    "from FlavorNet.models.predict import test\n",
    "test('tmp', model, dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
